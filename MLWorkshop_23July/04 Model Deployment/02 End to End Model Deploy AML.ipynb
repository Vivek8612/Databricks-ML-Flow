{"cells":[{"cell_type":"markdown","source":["## End to End ML Demo: Read Data, Build ML Model, Track with MLflow, ONNX, Deploy to ACI/AKS with MLflow\n\nIn this tutorial, we will use MLflow to train a model for rating wines and deploy it to Azure ML for real-time serving.\n\nThis guide consists of the following sections:\n\n#### Setup\n* Launch an Azure Databricks cluster\n* Install MLflow\n* Install the Azure ML SDK\n* Create or load an Azure ML Workspace\n* (Optional) Connect to an MLflow tracking server\n\n#### Training a model\n* Download training data\n* In an MLflow run, train and save an ElasticNet model for rating wines\n\n#### Building an Azure Container Image for model deployment\n* Use MLflow to build a Container Image for the trained model\n\n#### Deploying the model to \"dev\" using Azure Container Instances (ACI)\n* Create an ACI webservice deployment using the model's Container Image\n\n#### Querying the deployed model in \"dev\"\n* Load a sample input vector from the wine dataset\n* Evaluate the sample input vector by sending an HTTP request\n\n#### Deploying the model to production using Azure Kubernetes Service (AKS)\n* Option 1: Create a new AKS cluster\n* Option 2: Connect to an existing AKS cluster\n* Deploy to the model's image to the specified AKS cluster\n\n#### Querying the deployed model in production\n* Load a sample input vector from the wine dataset\n* Evaluate the sample input vector by sending an HTTP request\n\n#### Updating the production deployment\n* Train a new model\n* Build an Azure Container Image for the new model\n* Deploy the new model's image to the AKS cluster\n* Query the updated model\n\n#### Cleaning up the deployments\n* Terminate the \"dev\" ACI webservice\n* Terminate the production AKS webservice\n* Remove the AKS cluster from the Azure ML Workspace"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69aa306c-c0e6-45fd-900f-aa8f77f27220"}}},{"cell_type":"markdown","source":["### Note that the notebook will not run on the training environment as we don't have the ACS, AKS etc services available"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6906ed8-e1da-4434-9d89-0adec862c208"}}},{"cell_type":"markdown","source":["The dataset used for this example is the UCI ML repository wine ratings dataset on the quality of wines.\n\nOriginal Source: [UCI Machine Learning Repository \nWine Ratings Data Set](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n[Cortez et al., 2009] \nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\nModeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be11cb1a-f0e4-400f-b36c-c5f6961d4daf"}}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07b1767d-78bc-49da-955d-885f5fcf3df5"}}},{"cell_type":"markdown","source":["### Launch an Azure Databricks cluster\n\nIn order to run this notebook properly, it must be attached to an Azure Databricks cluster that satisfies the following requirements:\n  \n- Use a DBR with Python 3, this notebook is demoed with DBR 6.5"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6e7fe6c-2332-49f6-9061-d52552900963"}}},{"cell_type":"markdown","source":["### Install MLflow\n\nNext, install the MLflow Python library using the following steps:\n\n1. Create the library with the Source `Upload Python Egg or PyPI` and the versioned Pip library name:\n  - `mlflow` - if you want to always use the latest, else use syntax `mlflow=1.7.0` to get a dedicated version of MLflow\n  \n2. Attach the library to the cluster."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45851c38-4f1d-417b-ba96-d6b1cec03f83"}}},{"cell_type":"markdown","source":["### Install the Azure ML MLflow SDK, ONNX\n\nOnce a cluster has been launched with the configuration described in **Launch an Azure Databricks cluster**, install the Azure Machine Learning SDK using the following steps:\n\n1. Create the library with the Source ``Upload Python Egg or PyPI`` and the Pip library name:\n  - `azureml-mlflow`, `skl2onnx`, `onnxruntime`\n     \n2. Attach the library to the cluster."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7ed9ffd-2342-46af-8848-683648eb0c9f"}}},{"cell_type":"markdown","source":["### Create or load an Azure ML Workspace"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6ec247c-02e1-4b15-9d5e-2293c4abaddf"}}},{"cell_type":"markdown","source":["Before models can be deployed to Azure ML, an Azure ML Workspace must be created or obtained. The `azureml.core.Workspace.create()` function will load a workspace of a specified name or create one if it does not already exist. For more information about creating an Azure ML Workspace, see the [Azure ML Workspace management documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-workspace)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72922987-ef23-424b-8805-7dc54ca03a34"}}},{"cell_type":"code","source":["import azureml\nfrom azureml.core import Workspace\n\nworkspace_name = \"<WORKSPACE_NAME>\"\nworkspace_location=\"<WORKSPACE_LOCATION>\"\nresource_group = \"<RESOURCE_GROUP>\"\nsubscription_id = \"<SUBSCRIPTION_ID>\"\n\nworkspace = Workspace.create(name = workspace_name,\n                             subscription_id = subscription_id,\n                             resource_group = resource_group,\n                             location = workspace_location,\n                             exist_ok=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acc720a7-2a45-4c5a-b44a-c779d8408e89"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### (Optional) Connect to an MLflow tracking server\n\nMLflow can collect data about a model training session, such as validation accuracy. It can also save artifacts produced during the training session, such as a PySpark pipeline model.\n\nBy default, these data and artifacts are stored on the cluster's local filesystem. However, they can also be stored remotely using an [MLflow Tracking Server](https://mlflow.org/docs/latest/tracking.html)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d62b1246-9601-4cdb-a124-b9c94db4c227"}}},{"cell_type":"code","source":["import mlflow\nmlflow.__version__\n\n# We are using the hosted mlflow tracking server\n\n# If we want to use Azure ML MLflow tracking server, set the tracking URI\nazureml_mlflow_uri = workspace.get_mlflow_tracking_uri()\nmlflow.set_tracking_uri(azureml_mlflow_uri)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de8d3be0-1b82-43ff-b948-2eef42dd8298"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["experiment_name = \"test\"\nmlflow.set_experiment(experiment_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48f3dd4e-416a-4555-802c-aabfffb7db73"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Training a model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a485fe3d-28d2-479d-a260-6280977ad044"}}},{"cell_type":"markdown","source":["### Download training data \n\nFirst, download the [wine qualities dataset (published by Cortez et al.)](https://archive.ics.uci.edu/ml/datasets/wine+quality) that will be used to train the model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b0ce40f-5f00-4d51-9736-1b92aabdaf39"}}},{"cell_type":"code","source":["%sh wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"edc1d7fd-512a-4771-91cc-ab27a35aac33"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["wine_data_path = \"/databricks/driver/winequality-red.csv\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d275a95e-fdad-4d26-b5a8-be96329dba34"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### In an MLflow run, train and save an ElasticNet model for rating wines\n\nWe will train a model using Scikit-learn's Elastic Net regression module. We will fit the model inside a new MLflow run (training session), allowing us to save performance metrics, hyperparameter data, and model artifacts for future reference. If MLflow has been connected to a tracking server, this data will be persisted to the tracking server's file and artifact stores, allowing other users to view and download it. For more information about model tracking in MLflow, see the [MLflow tracking reference](https://www.mlflow.org/docs/latest/tracking.html).\n\nLater, we will use the saved MLflow model artifacts to deploy the trained model to Azure ML for real-time serving."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54eecf3b-8ab5-4ee7-89aa-26daff35dbb3"}}},{"cell_type":"code","source":["import os\nimport warnings\nimport sys\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\n\nimport mlflow\nimport mlflow.sklearn\nimport mlflow.onnx\nimport onnx\nimport skl2onnx\n\ndef eval_metrics(actual, pred):\n    rmse = np.sqrt(mean_squared_error(actual, pred))\n    mae = mean_absolute_error(actual, pred)\n    r2 = r2_score(actual, pred)\n    return rmse, mae, r2\n\n\ndef train_model(wine_data_path, model_path, alpha, l1_ratio):\n    warnings.filterwarnings(\"ignore\")\n    np.random.seed(40)\n\n    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n    data = pd.read_csv(wine_data_path, sep=None)\n\n    # Split the data into training and test sets. (0.75, 0.25) split.\n    train, test = train_test_split(data)\n\n    # The predicted column is \"quality\" which is a scalar from [3, 9]\n    train_x = train.drop([\"quality\"], axis=1)\n    test_x = test.drop([\"quality\"], axis=1)\n    train_y = train[[\"quality\"]]\n    test_y = test[[\"quality\"]]\n\n    # Start a new MLflow training run \n    with mlflow.start_run():\n        # Fit the Scikit-learn ElasticNet model\n        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n        lr.fit(train_x, train_y)\n\n        predicted_qualities = lr.predict(test_x)\n\n        # Evaluate the performance of the model using several accuracy metrics\n        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\n        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n        print(\"  RMSE: %s\" % rmse)\n        print(\"  MAE: %s\" % mae)\n        print(\"  R2: %s\" % r2)\n\n        # Log model hyperparameters and performance metrics to the MLflow tracking server\n        # (or to disk if no)\n        mlflow.log_param(\"alpha\", alpha)\n        mlflow.log_param(\"l1_ratio\", l1_ratio)\n        mlflow.log_metric(\"rmse\", rmse)\n        mlflow.log_metric(\"r2\", r2)\n        mlflow.log_metric(\"mae\", mae)\n\n        mlflow.sklearn.log_model(lr, model_path)\n        \n        \n        initial_type = [('float_input', skl2onnx.common.data_types.FloatTensorType([None, test_x.shape[1]]))]\n        onnx_model = skl2onnx.convert_sklearn(lr, initial_types=initial_type)\n        print(\"onnx_model.type:\", type(onnx_model))\n        mlflow.onnx.log_model(onnx_model, \"onnx-model\")\n        mlflow.set_tag(\"onnx_version\", onnx.__version__)\n        \n        return mlflow.active_run().info.run_uuid"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49f94261-8943-42e3-a2b5-78af61b4ac15"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["alpha_1 = 0.75\nl1_ratio_1 = 0.25\nmodel_path = 'model'\nrun_id1 = train_model(wine_data_path=wine_data_path, model_path=model_path, alpha=alpha_1, l1_ratio=l1_ratio_1)\nmodel_uri = \"runs:/\"+run_id1+\"/model\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49357469-c6c6-4cee-823a-d1e05ec2454e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Building an Azure Container Image for model deployment"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ceb3dabe-4b2a-43f6-ad32-eec366b73993"}}},{"cell_type":"markdown","source":["### Use MLflow to build a Container Image for the trained model\n\nWe will use the `mlflow.azuereml.build_image` function to build an Azure Container Image for the trained MLflow model. This function also registers the MLflow model with a specified Azure ML workspace. The resulting image can be deployed to Azure Container Instances (ACI) or Azure Kubernetes Service (AKS) for real-time serving."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"175d501d-7148-4bb0-b596-204c76b77dd8"}}},{"cell_type":"code","source":["import mlflow.azureml\n\nmodel_image, azure_model = mlflow.azureml.build_image(model_uri=model_uri, \n                                                      workspace=workspace, \n                                                      model_name=\"wine-rating-model\",\n                                                      image_name=\"wine-model-container-image\",\n                                                      description=\"Sklearn ElasticNet image for rating wines\", \n                                                      tags={\n                                                        \"alpha\": str(alpha_1),\n                                                        \"l1_ratio\": str(l1_ratio_1),\n                                                      },\n                                                      synchronous=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"836cccfe-4ddb-4451-9ac0-b332389cb065"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model_image.wait_for_creation(show_output=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b88aac14-a3b8-4a23-bbc6-3e436e543a59"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Deploying the model to \"dev\" using [Azure Container Instances (ACI)](https://docs.microsoft.com/en-us/azure/container-instances/)\n\nThe [ACI platform](https://docs.microsoft.com/en-us/azure/container-instances/) is the recommended environment for staging and developmental model deployments."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5780cbbf-5280-41d7-9336-453032ad0aa9"}}},{"cell_type":"markdown","source":["### Create an ACI webservice deployment using the model's Container Image\n\nUsing the Azure ML SDK, we will deploy the Container Image that we built for the trained MLflow model to ACI."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"643edb91-2019-4e0d-ac92-6e82c208eac3"}}},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice, Webservice\n\ndev_webservice_name = \"wine-model-dev\" # make sure this name is unique and doesnt already exist, else need to replace\ndev_webservice_deployment_config = AciWebservice.deploy_configuration()\ndev_webservice = Webservice.deploy_from_image(name=dev_webservice_name, image=model_image, deployment_config=dev_webservice_deployment_config, workspace=workspace)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e81f261-7a30-4ea2-adaa-22b3efa7cb53"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dev_webservice.wait_for_deployment()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51ace13b-df3a-4714-9cf6-8c8a0875b24b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Querying the deployed model in \"dev\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62b2db19-518e-4b5e-8adb-d18840c780ef"}}},{"cell_type":"markdown","source":["### Load a sample input vector from the wine dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9265550d-8a83-4e44-96e2-509a6bd12f69"}}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nfrom sklearn import datasets\n\ndata = pd.read_csv(wine_data_path, sep=None)\ntrain, _ = train_test_split(data)\ntrain_x = train.drop([\"quality\"], axis=1)\nsample = train_x.iloc[[0]]\nquery_input = list(sample.as_matrix().flatten())\nsample_json = sample.to_json(orient=\"split\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"676b24bb-8596-4312-9bcc-3851e5f9bd4b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Evaluate the sample input vector by sending an HTTP request\nWe will query the ACI webservice's scoring endpoint by sending an HTTP POST request that contains the input vector."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9b9a525-7504-4064-bfa1-d01d4473b75c"}}},{"cell_type":"code","source":["import requests\nimport json\n\ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n    \n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=inputs, headers=headers)\n  print(\"Response: {}\".format(response.text))\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  return preds"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21701a14-0e70-497c-b6a4-d5a904aecb7b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dev_scoring_uri = dev_webservice.scoring_uri"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eab3c659-cedd-49ab-b0e3-c7c75dd1e57b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dev_prediction = query_endpoint_example(scoring_uri=dev_scoring_uri, inputs=sample_json)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fb51549-6d35-49ab-8c54-cf4d5d619199"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Deploying the model to production using [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/en-us/services/kubernetes-service/)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4dfadd84-8a84-4b24-9ce1-915c61add8a5"}}},{"cell_type":"markdown","source":["### Option 1: Create a new AKS cluster\n\nIf you do not have an active AKS cluster for model deployment, you can create one using the Azure ML SDK."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7386a195-a4dd-42c4-a60d-95d92ab875b8"}}},{"cell_type":"code","source":["from azureml.core.compute import AksCompute, ComputeTarget\n\n# Use the default configuration (you can also provide parameters to customize this)\nprov_config = AksCompute.provisioning_configuration()\n\naks_cluster_name = \"wine-prod\" \n# Create the cluster\naks_target = ComputeTarget.create(workspace = workspace, \n                                  name = aks_cluster_name, \n                                  provisioning_configuration = prov_config)\n\n# Wait for the create process to complete\naks_target.wait_for_completion(show_output = True)\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb20b185-9d10-4aa7-b43b-1fabb1be1890"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Option 2: Connect to an existing AKS cluster\n\nIf you already have any active AKS cluster running, you can add it to your Workspace using the Azure ML SDK."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94dbbf8d-7d47-4b95-b256-ce5c274013ad"}}},{"cell_type":"code","source":["from azureml.core.compute import AksCompute, ComputeTarget\n\n# Get the resource id from https://porta..azure.com -> Find your resource group -> click on the Kubernetes service -> Properties\nresource_id = \"/subscriptions/<your subscription id>/resourcegroups/<your resource group>/providers/Microsoft.ContainerService/managedClusters/<your aks service name>\"\n\n\n# Give the cluster a local name\ncluster_name = \"<CLUSTER_NAME>\"\n\n# Attatch the cluster to your workgroup\naks_target = AksCompute.attach(workspace=workspace, name=cluster_name, resource_id=resource_id)\n\ncompute = ComputeTarget.attach(workspace, cluster_name, attach_config)\n\n# Wait for the operation to complete\ncompute.wait_for_completion(True)\nprint(compute.provisioning_state)\nprint(compute.provisioning_errors)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f457ed3b-5c46-48c7-9b30-9f136014629c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Deploy to the model's image to the specified AKS cluster"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddf0cbf8-9020-4ffb-9497-ee35259c548a"}}},{"cell_type":"code","source":["from azureml.core.webservice import Webservice, AksWebservice\n\n# Set configuration and service name\nprod_webservice_name = \"wine-model-prod\"\nprod_webservice_deployment_config = AksWebservice.deploy_configuration()\n\n# Deploy from image\nprod_webservice = Webservice.deploy_from_image(workspace = workspace, \n                                               name = prod_webservice_name,\n                                               image = model_image,\n                                               deployment_config = prod_webservice_deployment_config,\n                                               deployment_target = aks_target)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb23657d-a9fe-48a3-b580-f7503d373a33"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Wait for the deployment to complete\nprod_webservice.wait_for_deployment(show_output = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6951dece-ea8f-4cb8-853b-770fb7490479"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Querying the deployed model in production"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3ab3888-80df-4b0d-aebd-88cb6a09c607"}}},{"cell_type":"markdown","source":["### Load a sample input vector from the wine dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e478f02a-02c4-4cf7-a4a6-b62cdb83b4d8"}}},{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nfrom sklearn import datasets\n\ndata = pd.read_csv(wine_data_path, sep=None)\ntrain, _ = train_test_split(data)\ntrain_x = train.drop([\"quality\"], axis=1)\nsample = train_x.iloc[[0]]\nquery_input = list(sample.as_matrix().flatten())\nsample_json = sample.to_json(orient=\"split\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c6f2ae6-9a05-45df-a390-cd1788dc1bc9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Evaluate the sample input vector by sending an HTTP request\nWe will query the AKS webservice's scoring endpoint by sending an HTTP POST request that includes the input vector. The production AKS deployment may require an authorization token (service key) for queries. We will include this key in the HTTP request header."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25a0b54b-baf9-4bac-ba1f-f47b823f6185"}}},{"cell_type":"code","source":["import requests\nimport json\n\ndef query_endpoint_example(scoring_uri, inputs, service_key=None):\n  headers = {\n    \"Content-Type\": \"application/json\",\n  }\n  if service_key is not None:\n    headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=service_key)\n    \n  print(\"Sending batch prediction request with inputs: {}\".format(inputs))\n  response = requests.post(scoring_uri, data=inputs, headers=headers)\n  preds = json.loads(response.text)\n  print(\"Received response: {}\".format(preds))\n  return preds"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58bca34a-f921-473f-9faf-8c2035005e75"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["prod_scoring_uri = prod_webservice.scoring_uri\nprod_service_key = prod_webservice.get_keys()[0] if len(prod_webservice.get_keys()) > 0 else None"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1aea366-542f-43e4-8370-cb8bca59e8aa"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["prod_prediction = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=sample_json)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54a05e50-f50f-4fae-837c-b0d3b83661dd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Updating the production deployment"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0fc5a25-0e36-4e87-a920-a7b922f6e9f5"}}},{"cell_type":"markdown","source":["### Train a new model\nFirst, we will train a new ElasticNet model with updated hyperparameters."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30a9a4cd-0361-4ac8-b95d-b9ed53dac5b8"}}},{"cell_type":"code","source":["alpha_2 = 0.5\nl1_ratio_2 = 0.8\nrun_id2 = train_model(wine_data_path=wine_data_path, model_path=model_path, alpha=alpha_2, l1_ratio=l1_ratio_2)\nmodel_uri = \"runs:/\"+run_id2+\"/model\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fdf2aaf-2bec-4cbe-86ac-fa2f0c85dcef"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Build an Azure Container Image for the new model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a13fe01-9c20-4a8a-93ac-9072b3aa2f61"}}},{"cell_type":"code","source":["import mlflow.azureml\n\nmodel_image_updated, azure_model_updated = mlflow.azureml.build_image(model_uri=model_uri,\n                                                                      workspace=workspace, \n                                                                      model_name=\"wine-rating-model\",\n                                                                      image_name=\"wine-model-container-image\",\n                                                                      description=\"Sklearn ElasticNet image for rating wines\", \n                                                                      tags={\n                                                                        \"alpha\": str(alpha_2),\n                                                                        \"l1_ratio\": str(l1_ratio_2),\n                                                                      },\n                                                                      synchronous=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e8d7429-3ff2-4a97-a7f2-544aa6e8c0ab"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model_image_updated.wait_for_creation(show_output=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87754e89-15db-49c2-952f-14a967451994"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Deploy the new model's image to the AKS cluster\n\nUsing the [azureml.core.webservice.AksWebservice.update()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.akswebservice?view=azure-ml-py#update) function, we will replace the deployment's existing model image with the new model image."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b80dddd3-4e0d-4dcc-b26e-cc79f1992878"}}},{"cell_type":"code","source":["prod_webservice.update(image=model_image_updated)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1078d6ee-5213-4b4d-be14-ba26b1f6cb9a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["prod_webservice.wait_for_deployment(show_output = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15300b99-1a46-490b-925c-407620c4ae8a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Query the updated model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a95a77b-febd-4d6c-88bd-900698dbcf6b"}}},{"cell_type":"code","source":["prod_prediction_updated = query_endpoint_example(scoring_uri=prod_scoring_uri, service_key=prod_service_key, inputs=sample_json)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e5a65a6-5095-437a-9b97-f8bc964fc59b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Cleaning up the deployments"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d3015cd-c86c-4041-b60a-c83edf7a570c"}}},{"cell_type":"markdown","source":["### Terminate the \"dev\" ACI webservice\n\nBecause ACI manages compute resources on your behalf, deleting the \"dev\" ACI webservice will remove all resources associated with the \"dev\" model deployment"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f458a17-757b-48d1-908b-0914adf83bbf"}}},{"cell_type":"code","source":["dev_webservice.delete()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c124aef-53c4-44cb-9413-6918c1997334"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Terminate the production AKS webservice\n\nThis terminates the real-time serving webservice running on the specified AKS cluster. It **does not** terminate the AKS cluster."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68ed9c71-7a7b-422f-91d8-cb8daf20d387"}}},{"cell_type":"code","source":["prod_webservice.delete()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de503bc4-4c7e-47bc-9731-b691b8fb8c22"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Remove the AKS cluster from the Azure ML Workspace\n\nIf the cluster was created using the Azure ML SDK (see **Option 1: Create a new AKS cluster**), removing it from the Azure ML Workspace will terminate the cluster, including all of its compute resources and deployments.\n\nIf the cluster was created independently (see **Option 2: Connect to an existing AKS cluster**), it will remain active after removal from the Azure ML Workspace."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1c3d976-d662-419a-b19d-2ca64d264b89"}}},{"cell_type":"code","source":["aks_target.delete()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6f5b736-a8f3-4936-8c67-c4066a2257b1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"208fc442-8dbf-4959-a951-6ece20ce692d"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"02 End to End Model Deploy AML","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3256439173735569}},"nbformat":4,"nbformat_minor":0}
