{"cells":[{"cell_type":"code","source":["%fs ls\n/databricks-datasets/bikeSharing/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Let's use the Bike Sharing Data as an example","showTitle":true,"inputWidgets":{},"nuid":"bebcec54-1c5e-4710-ab1c-165a75e86057"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["This notebook will - for the most part - follow the pattern of:\n- 'Here's how do to **X** in pandas'\n- 'Here's how to do **X** in Koalas'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"53866f91-1335-41d1-8fe4-5b8612e03f08"}}},{"cell_type":"code","source":["import pandas as pd\n\npandas_bike = pd.read_csv('/dbfs/databricks-datasets/bikeSharing/data-001/day.csv')\n\npandas_bike.head(15)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Reading Data in Pandas","showTitle":true,"inputWidgets":{},"nuid":"0d1eef32-5ac0-427e-85d1-34721ad660ac"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import databricks.koalas as ks\n\nkoalas_bike = ks.read_csv('/databricks-datasets/bikeSharing/data-001/day.csv')\n\nkoalas_bike.head(15)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Reading Data in Koalas","showTitle":true,"inputWidgets":{},"nuid":"258c4849-b5cc-4232-89ac-bccd5a1f0d9c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pandas_bike.describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Getting Summary Statistics in Pandas","showTitle":true,"inputWidgets":{},"nuid":"bbe56a77-1804-4325-8905-b03fa6a1f693"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike.describe()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Getting Summary Statistics in Koalas ","showTitle":true,"inputWidgets":{},"nuid":"f74e2914-b656-4401-8953-9ff037712304"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["You'll notice that calling `describe()` in Koalas kicks off a couple spark jobs - again this is because the data frame is distributed. Because the aggregates required for the `describe()` output require passing data across nodes, this creates stage boundaries."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cf79e0f-9e97-4cf6-94e5-9b8618efef5b"}}},{"cell_type":"code","source":["pandas_bike.sort_values(by='temp').head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Sorting by Columns in Pandas","showTitle":true,"inputWidgets":{},"nuid":"dedfa1d5-0b7f-42b4-b93a-37bb90043f1e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike.sort_values(by='temp').head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Sorting by Columns in Koalas ","showTitle":true,"inputWidgets":{},"nuid":"58cfd394-97cd-4112-84b8-2ef300e16efe"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pandas_bike.transpose()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Transposing Data in Pandas","showTitle":true,"inputWidgets":{},"nuid":"eee0a663-2633-45c2-be53-37515da6f09f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike[['season','holiday']].transpose()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Transposing Data in Koalas ","showTitle":true,"inputWidgets":{},"nuid":"b006d1a8-ad6c-4efd-a723-f3c994150fe1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Best Practice** DataFrame.transpose() will fail when the number of rows is more than the value of compute.max_rows, which is set to 1000 by default. This is to prevent users from unknowingly executing expensive operations. In Koalas, you can easily reset the default compute.max_rows."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3cb5849-45b6-4b9d-b080-2dd3200cf5bd"}}},{"cell_type":"code","source":["ks.get_option('compute.max_rows')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"43b287ed-46aa-4ad8-9920-928c8610dce5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ks.set_option('compute.max_rows',2000)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b174f9a5-b497-46e2-a352-66cf4ff5f706"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ks.get_option('compute.max_rows')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66361db3-72b9-47e4-a299-3345d9bcc164"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pandas_bike['season']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Selecting Data in Pandas","showTitle":true,"inputWidgets":{},"nuid":"b5e4cf38-2f23-4270-96b7-70c8f8f42528"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike['season']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd116f9f-a2db-4dee-85be-2548de9c0da7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note that when selecting a single row using Koalas, it returns a series."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87815102-4611-485e-b017-f6e01d8d0877"}}},{"cell_type":"code","source":["type(koalas_bike['season'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"61cfa16e-1ab0-4f17-9e9f-aeb634fe16b6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["However, when multiple columns are selected, it returns a dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e22d7513-5d00-4be6-ae11-c5dde37d162c"}}},{"cell_type":"code","source":["type(koalas_bike[['temp','season']])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c2c2ca0-ad53-4025-9dc7-ba34b93d0641"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pandas_bike.iloc[:2,:4]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Slicing Rows and Columns in Pandas","showTitle":true,"inputWidgets":{},"nuid":"9062ddaf-efd0-4770-a689-e8ac5eaef5ec"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike.iloc[:2, :4]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Slicing Rows and Columns in Koalas ","showTitle":true,"inputWidgets":{},"nuid":"71b64c65-785b-4631-84a4-7629e4e3b40c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Best Practice:** By default, Koalas disallows adding columns coming from different DataFrames or Series to a Koalas DataFrame as adding columns requires join operations which are generally expensive. This operation can be enabled by setting compute.ops_on_diff_frames to True, but this could affect performance"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ae344a6-2dd6-45f6-99a4-785b8ffd9b03"}}},{"cell_type":"code","source":["ks.set_option(\"compute.ops_on_diff_frames\", True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"255bc8b0-3af2-4f3f-9c79-2885f9c8b791"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ks.get_option('compute.ops_on_diff_frames')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"599f73a2-bc65-4b81-85d8-5d6bf7b733c0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Exercise 1:\nWe are looking to get a list of the top selling items that fall between 25% of the median price. Using Koalas please do the following\n- Read in the data from the `databricks-datasets/definitive-guide/data/retail-data/all/online-retail-dataset.csv` path\n- Filter the Koalas DF such that the values fall between the 1st and 3rd quantiles for the `UnitPrice` column\n- Sort the resulting DF by `Quantity`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a2b22464-9ab7-4618-a379-634268a9e4fb"}}},{"cell_type":"code","source":["import databricks.koalas as ks\n\npath = 'databricks-datasets/definitive-guide/data/retail-data/all/online-retail-dataset.csv'\n\n# Read in the data\nkoalas_retail = ks.read_csv(path)\n\n# Get the quantile values \nkoalas_retail.UnitPrice.describe()\n\n#Filter so all observations are between 1st and 3rd quantile\nkoalas_retail[(koalas_retail['UnitPrice'] > 1.25) & (koalas_retail['UnitPrice'] < 4.13)].sort_values(by='Quantity', ascending = False).head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77fb2c9a-ed41-490d-8419-0dce4cc0794b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import numpy as np\npandas_bike[['temp', 'season']].apply(np.cumsum).head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Applying a Function to a Dataframe in Pandas","showTitle":true,"inputWidgets":{},"nuid":"c59197dc-4976-4e29-99a4-c3013088a775"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike[['temp', 'season']].apply(np.cumsum).head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Applying a Function to a Dataframe in Koalas ","showTitle":true,"inputWidgets":{},"nuid":"f873c601-1426-46bd-bddb-7e82f179c51d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note that the default index is zero - however, the `index` can be set."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70d9b0e1-a7c4-43ec-939c-b6f2319855b0"}}},{"cell_type":"markdown","source":["**Best Practices** It's always a good idea to specify the return type hint for for Spark's return type internally when applying a UDF to a Koalas Dataframe. If the return type hint is not specified, Koalas runs the function once for a small sample to infer the Spark return type which can be fairly expensive"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e3a7da8-d5a7-450e-893f-7a990f92f98e"}}},{"cell_type":"markdown","source":["Note that global `apply` in Koalas doesn't support global aggs. This is by design. However, you can use the `computer_shortcut` limit to get around this limitation if data is small enough"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb22f5cb-c906-4944-bb80-03173fa0826a"}}},{"cell_type":"code","source":["pandas_bike.groupby('mnth').head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Grouping Data in Pandas","showTitle":true,"inputWidgets":{},"nuid":"ca2804ad-54e1-40ba-ac3e-81f80df29837"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike.groupby('mnth').head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f04c5e1c-c0ad-45f7-80e4-b48362e7148a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Beyond data manipulation, Koalas aslo has code coverage for visual functions as well."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b253f5f9-9792-42fb-9a72-9a2b5ce82f1e"}}},{"cell_type":"code","source":["display(pandas_bike.plot.line(x='dteday',y='temp'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Building a Line Chart in Pandas","showTitle":true,"inputWidgets":{},"nuid":"b481c864-8f3f-48cb-a31b-b8e49d681dbd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(koalas_bike.plot.line(x='dteday',y='temp'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Building a Line Chart in Koalas","showTitle":true,"inputWidgets":{},"nuid":"74c16f5d-f073-456d-a704-e02a8b413090"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(pandas_bike.plot.scatter(x='temp', y='windspeed',c='weathersit', colormap='gist_heat'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Building a Scatter Plot with Colormap in Pandas","showTitle":true,"inputWidgets":{},"nuid":"a67cb5ff-cae5-41d9-868c-176b97624f8f"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(koalas_bike.plot.scatter(x='temp', y='windspeed',c='weathersit', colormap='gist_heat'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Building a Scatter Plot with Colormap in Koalas","showTitle":true,"inputWidgets":{},"nuid":"30ce7b5c-7f40-4646-b23e-8e62c47be1f3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Exercise 2:\nLet's build a plot that uses the retail data from **Exercise 1** to look at the top 20 selling products. Please use Koalas to do the following:\n- Group by the item\n- Select the 20 items that have sold the most quantity \n- Create a bar chart that displays the item description X quantity"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c843ec92-193a-4fe3-8d8a-8f93771533f4"}}},{"cell_type":"code","source":["# Group the dataframe, sum by group, sort by total items\ngrouped_df = koalas_retail.groupby('Description',as_index=False).sum().sort_values(by ='Quantity', ascending = False).head(20)\n\n# Make the bar chart\ndisplay(grouped_df.plot.bar(x='Description', y = 'Quantity'))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7118ff4-8db5-417f-9ba0-1322a3fd4b98"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## When and Why to convert across Pandas and Koalas \nBecause Koalas only have about 70% converage of Pandas - not to mention some pandas operations fundamentally aren't able to be distributed - the workflow for implementing functions that exist in Pandas and *not* in Koalas and vice versa is to use the `to_Pandas()` and `to_Koalas` syntax"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"958826af-f7d2-46e2-b633-281bf5e3763f"}}},{"cell_type":"code","source":["convert = ks.from_pandas(pandas_bike)\ntype(convert)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Converting a Pandas Dataframe to a Koalas Dataframe","showTitle":true,"inputWidgets":{},"nuid":"6d74e5d1-d7cf-4837-80ac-322fbac01575"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["convert = koalas_bike.to_pandas()\ntype(convert)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Converting a Koalas Dataframe to a Pandas Dataframe","showTitle":true,"inputWidgets":{},"nuid":"bb31e5c8-92df-4658-8195-790d1d56d86f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Note**: This will collect all your data on the driver. If the data is larger than the amount of memory on the driver, this will return an *Out of Memory* error"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a79ba4b3-249e-4d01-bf10-dd69101f2044"}}},{"cell_type":"code","source":["pandas_bike.index.to_list()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Converting to an Index/Column to a List in Pandas","showTitle":true,"inputWidgets":{},"nuid":"0f153654-3157-4413-8b2f-fa20e3725090"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["You'll notice that the equivalent in Koalas is not possible because it requires collecting all the data back to the driver."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a525a6dd-3398-4806-89fe-958b6ff8388f"}}},{"cell_type":"code","source":["koalas_bike.index.to_list()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f7ca072-ab30-453f-bdaf-7b807873ff1e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["In order to work around this, you'll have to convert your Koalas DF to a Pandas on and call `to_list()` from there"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83e6214f-84cd-4454-9c1f-80815b15feb9"}}},{"cell_type":"code","source":["koalas_bike.to_pandas().index.to_list()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Converting to an Index/Column to a List in Koalas","showTitle":true,"inputWidgets":{},"nuid":"27c5a66a-db6b-42ff-9568-8c78a1c83fbe"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Natively Supporting Pandas Objects"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f9da02d-6d8b-4670-9ddf-6ebbe7893ccb"}}},{"cell_type":"code","source":["# Adding timestamp column to pandas df\npandas_bike['timestamp'] = pd.Timestamp('19960524')\nkoalas_with_timestamp = ks.from_pandas(pandas_bike)\n\n# Quickly view the data \nkoalas_with_timestamp.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e059cea-52ee-4853-8f96-b641f336ecfc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Check that it's a Koalas DF\ntype(koalas_with_timestamp)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d51b43b-f112-46a9-acde-d86bfb558acc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Koalas has Koalas specific functions that support distributing a pandas function across a Koalas dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e37ee3f-0302-402b-bda1-f2b8146bd5b8"}}},{"cell_type":"code","source":["date_range = pd.date_range('1996-05-24', periods=731, freq='1D1min')\nkdf = ks.DataFrame({'Test': [\"timestamp\"]}, index = date_range)\nkdf.dtypes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Distributing a Pandas Function in Koalas ","showTitle":true,"inputWidgets":{},"nuid":"fa7d0714-62db-414c-82e4-d7cee4a918f1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["kdf.map_in_pandas(func=lambda pdf: pdf.between_time('0:15', '0:16'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41962172-af1a-4700-ba47-41a5d63adf7b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Using SQL with Koalas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79f579fa-2d80-4bb0-95d7-2c124671b02e"}}},{"cell_type":"code","source":["ks.sql('select * from {koalas_bike} where weekday = 6').head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3c3053b-d817-4c5c-92cc-a657ac3ad467"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ks.sql('SELECT ks.temp, pd.atemp FROM {koalas_bike} ks INNER JOIN {pandas_bike} pd ON ks.instant = pd.instant ORDER BY ks.temp, pd.atemp').head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Using SQL to join a Koalas Dataframe to a Pandas Dataframe","showTitle":true,"inputWidgets":{},"nuid":"4a6ee3ea-4738-4a57-a37d-4e8bbbc9ce8f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Exercise 3: \nRecreate the solution from **Exercise 2** using Spark SQL and Koalas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0927245a-20f6-4bb1-ae82-0a72bea07d66"}}},{"cell_type":"code","source":["# Create the DF from the SQL query\nplot_df = ks.sql('select Description, sum(quantity) as total_quantity from {koalas_retail} group by Description order by sum(quantity) desc limit 20')\n\n# Plot using Koalas \ndisplay(grouped_df.plot.bar(x='Description', y = 'Quantity'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d143233f-a045-4c65-99a2-5eb5b813c27e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Working with Pyspark in Koalas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fb39884-4a46-46d8-8829-c42e24bf304f"}}},{"cell_type":"code","source":["spark_df = koalas_bike.to_spark()\ntype(spark_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Converting a Koalas Dataframe to a Pyspark Dataframe","showTitle":true,"inputWidgets":{},"nuid":"2140a846-d8e4-46b1-85bb-860322620be3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["koalas_bike_from_spark = spark_df.to_koalas()\ntype(koalas_bike_from_spark)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Converting a Spark Dataframe to a Koalas Dataframe","showTitle":true,"inputWidgets":{},"nuid":"a52f6935-25af-4429-a720-f4d587e14ef5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note that the conversion from a Spark dataframe to a Koalas dataframe can cause an OOM error if the default index is of type `sequence`. You can change the index by using the `compute.default_index_type (default = sequence)`. However, if the index must be a sequence you should use a distributed sequence"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"adfec835-2f54-42b4-a12d-dee4306efa58"}}},{"cell_type":"markdown","source":["**Best Practice**: Best Practice: Converting from a PySpark DataFrame to Koalas DataFrame can have some overhead because it requires creating a new default index internally â€“ PySpark DataFrames do not have indices. You can avoid this overhead by specifying the column that can be used as an index column. See the Default Index type for more detail."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"893e0fe8-eb43-4a96-bb14-6babeb86f0f6"}}},{"cell_type":"markdown","source":["### Using Koalas to check the Spark Execution plan"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8b86a3c-6e14-4025-99cb-630a9c46e6fd"}}},{"cell_type":"code","source":["koalas_bike.explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b03ba6d-58e8-495a-b96b-2fff928a4904"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Best Practice**: Using the `explain()` function can be really useful to optimize your spark code"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9adb547b-8187-43da-9970-745423524576"}}},{"cell_type":"code","source":["cache_df = koalas_bike.loc[koalas_bike['cnt']>850]\ncache_df.cache()\ncache_df.explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Caching a Dataframe in Koalas ","showTitle":true,"inputWidgets":{},"nuid":"ac401a1b-8a99-4b8c-91ac-f8b878e6c747"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note you can use `unpersist()` to remove your dataframe from cached memory"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb495878-5e2f-47f0-be47-6f5faefd2aaa"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Koalas Working Demo Solutions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3256439173735815}},"nbformat":4,"nbformat_minor":0}
