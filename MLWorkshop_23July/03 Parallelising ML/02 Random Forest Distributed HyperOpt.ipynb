{"cells":[{"cell_type":"markdown","source":["#Understanding Parallelization of Machine Learning Algorithms in Apache Spark™\n\n##Parallelize Hyperparameter Tuning with Hyperopt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8242918-1b0c-4d30-8d44-e042512ff141"}}},{"cell_type":"markdown","source":["The dataset used for this example is Bank marketing. Given a set of features about a customer can we predict whether the person will open a term deposit account.\n\nOriginal Source: [UCI Machine Learning Repository \nBank Marketing Data Set](https://archive.ics.uci.edu/ml/datasets/bank+marketing)\n[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n\nRequirements: Ensure that the data prep notebooks have been run, should have been done prior to workshop"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db674a7f-ac6b-431e-b9f8-d7bfa24d6533"}}},{"cell_type":"markdown","source":["####Attribute Information:\n\n####Input variables:\nbank client data:\n```\n1 - age (numeric)\n2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n5 - default: has credit in default? (categorical: 'no','yes','unknown')\n6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n7 - loan: has personal loan? (categorical: 'no','yes','unknown')\nrelated with the last contact of the current campaign:\n8 - contact: contact communication type (categorical: 'cellular','telephone') \n9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\nother attributes:\n12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n14 - previous: number of contacts performed before this campaign and for this client (numeric)\n15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\nsocial and economic context attributes\n16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n17 - cons.price.idx: consumer price index - monthly indicator (numeric) \n18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n20 - nr.employed: number of employees - quarterly indicator (numeric)\n\nOutput variable (desired target):\n21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91a65bf3-1921-4748-81f8-9383e147edab"}}},{"cell_type":"code","source":["# One additional setup notebook required to run\ndbutils.notebook.run(\"../Utils/02 Feature Engineering for Distributed HyperOpt\", 0, {\"databricksUsername\":\"test\"})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08b7bd59-4b91-420f-865b-410d3d64a679"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["train_data_path = \"/ml-workshop-datasets/employee/delta/trainingData\"\ntest_data_path = \"/ml-workshop-datasets/employee/delta/testData\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d66dd15-7f8c-4042-828d-e02206ceed1e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Introduction\nIf using the sklearn implementation, one can choose to distribute the model evaluation tasks using distributed HyperOpt in two ways. First one can run 1 core per model, this means that the number of concurrent model evaluations is equal to the total number of cores on the workers. Alternatively one can run 1 model per worker, using all the cores on a worker for optimizing one model. In this case the number of concurrent model evaluations is equal to the number of workers. This setup allows model evaluations to be performed faster if one is willing to run a larger cluster. It requires to set the Spark option spark.task.cpus to the number of cores of the worker nodes. \n\nIn this notebook a sklearn setup with 1 core per model and distributed HyperOpt will be demonstrated.\n\n#### Note: the data used in this demo is created by the 'Feature Engineering for Distributed HyperOpt' notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ee716cb-cfe3-4915-ba0b-2113b2eaef0b"}}},{"cell_type":"markdown","source":["## Data description recap\nBank client data:\n- age (numeric)\n- job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n- marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n- education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n- default: has credit in default? (categorical: 'no','yes','unknown')\n- housing: has housing loan? (categorical: 'no','yes','unknown')\n- loan: has personal loan? (categorical: 'no','yes','unknown')\n\nRelated with the last contact of the current campaign:\n- contact: contact communication type (categorical: 'cellular','telephone') \n- month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n- day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n- duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n\nOther attributes:\n- campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n- pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n- previous: number of contacts performed before this campaign and for this client (numeric)\n- poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n\nOutput variable (desired target):\n21 - y - has the client subscribed a term deposit? (binary: 'yes','no')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"faa6d04d-f83b-4dae-b7b6-0a182611dd34"}}},{"cell_type":"markdown","source":["## Sklearn with distributed HyperOpt"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68b5dd2f-ecbb-4781-acf0-823bd34a3a62"}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport os.path\nimport datetime\nfrom sklearn.ensemble.forest import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\nimport mlflow\n\nimport hyperopt as hp\nfrom hyperopt import fmin, rand, tpe, hp, Trials, exceptions, space_eval, STATUS_FAIL, STATUS_OK\nfrom hyperopt import SparkTrials"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb77caa9-6301-463a-b9bf-a0cdea6ef29c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Random forest training logic\nThe following functions are defined:\n- read_data - reads numpy data from a path and return X and y data matrices\n- get_model - takes a set of hyperparameters and returns a parametrized random forest model\n- train - takes a set of hyperparameters and returns a trained model and the out of bootstrap error"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"573a5771-7378-40bd-9d40-2f9be6d5761f"}}},{"cell_type":"code","source":["def read_data(path):  \n  \"\"\"\n  This method reads numpy data from disk\n\n  :param path: The path to the file containing the data\n  :return: X and y numpy arrays\n  \"\"\"\n  \n  input_data = np.load(path)\n  \n  X = input_data[:,:-1]\n  y = input_data[:,-1]\n  \n  return X, y\n\n\ndef get_model(params):\n  \"\"\"\n  This function creates a random forest model using the given hyperparameters.\n  \n  :param params: This dict of parameters specifies hyperparameters\n  :return: an untrained model \n  \"\"\"\n  min_samples_leaf = int(params['min_samples_leaf'])\n  criterion = params['criterion']\n  n_estimators = int(params['n_estimators'])\n  random_state = params['seed']\n    \n  model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion=criterion,\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_samples_leaf=min_samples_leaf,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            n_estimators=n_estimators, n_jobs=1, oob_score=True, random_state=random_state,\n            verbose=0, warm_start=False)\n  \n  return model\n  \n  \ndef train(params):\n  \"\"\"\n  This function trains and evaluates a model using the given hyperparameters.\n  \n  :param params: This dict of parameters specifies hyperparameters.\n  :return: a trained model and the resulting validation loss\n  \"\"\"\n\n  training_path = \"/dbfs/ml-workshop-datasets/employee/numpy/train.npy\"\n  X, y = read_data(training_path)\n      \n  model = get_model(params)\n  model.fit(X, y)\n  \n  return model, 1 - model.oob_score_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fe94384-db4f-4e80-9ee3-b663e97810ae"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Run distrbuted HyperOpt\nKey components for running distributed hyperopt are:\n- evaluate_hyperparams - a helper function that extracts the out of boostrap score for a trained model\n- search_space - the parameter space that HyperOpt will use for its search\n- algo - the type of algorithm used by HyperOpt (Tree of Parzen Estimators or random search)\n- spark_trails - a helper object that makes HyperOpt distributed\n- fmin - the function that performs the search of the hyper parameter space"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66c43d4b-1a7a-43e9-aa3d-297f4bf86c95"}}},{"cell_type":"code","source":["def evaluate_hyperparams(params):\n  \"\"\"\n  This method will be passed to `hyperopt.fmin()`.  It fits and evaluates the model using the given hyperparameters to get the validation loss.\n  \n  :param params: This dict of parameters specifies hyperparameter values to test.\n  :return: dict with fields 'loss' (scalar loss) and 'status' (success/failure status of run)\n  \"\"\"\n  \n  # Train the model\n  model, score = train(params)\n        \n  return {'loss': score, 'status': STATUS_OK}\n\n\n# The hyper parameter space to search\ncriteria = ['gini', 'entropy']\nsearch_space = {\n  'seed': hp.randint('seed', 1000000),\n  'n_estimators': hp.uniform('n_estimators', 10, 500),\n  'min_samples_leaf': hp.uniform('min_samples_leaf', 1, 20),\n  'criterion': hp.choice('criterion', criteria)\n}\n\n# The algoritm to perform the parameter search\nalgo=tpe.suggest  # Tree of Parzen Estimators (a \"Bayesian\" method)\n#algo=random.suggest  # Random search\n\n# Configure parallelization\nspark_trials = SparkTrials(parallelism=4)\n\n# name the run\nnow = datetime.datetime.now()\nrun_name = now.strftime(\"%Y%m%d-%H%M\")\n\n# Execute the search with MLFlow support\nwith mlflow.start_run(run_name=run_name):\n  argmin = fmin(\n    fn=evaluate_hyperparams,\n    space=search_space,\n    algo=algo,\n    max_evals=40,\n    trials=spark_trials)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ad68e23-093f-4d99-a8d3-42726bdc4db6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["The optimal hyperparameters are now set in argmin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4685dfc9-7235-4b5b-ad33-1ec93bf6854a"}}},{"cell_type":"code","source":["argmin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb422030-29f1-4427-81a0-4b3f692bcfaa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Recreate the best model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"929b5a04-2c39-431d-a84c-121ca0f5ebc4"}}},{"cell_type":"code","source":["params = {'criterion': 1,\n 'min_samples_leaf': 8.95432038529209,\n 'n_estimators': 173.33988549738507,\n 'seed': 569904}\n\n# The argmin contains indices for gini and entropy, we have to fix this\nparams['criterion'] = criteria[params['criterion']]\n\nmodel, loss = train(params)\n\nprint(\"Validation loss: {}\".format(loss))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"242de21d-b523-43c8-b34b-87129d3ea2b9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["model"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"55ea3aa4-c164-4761-bcde-296325f8ba22"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Validate on the test data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b959abe-ac30-4755-a7f1-c7b1fc134162"}}},{"cell_type":"code","source":["# Read the data and create a test datagenerator\ntest_path = \"/dbfs/ml-workshop-datasets/employee/numpy/test.npy\"\nX_test, y_test = read_data(test_path)\n\npredictions = model.predict(X_test)\n\n# Output some metrics\nprint(\"Accuracy: {}\".format(accuracy_score(y_test, predictions)))\nprint(classification_report(y_test, predictions))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1db2a933-7be6-4935-8401-4ecaa5c30534"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Use MLflow to show the hyperparameter effects in a parallel coordinates plot.\n\nSelect the Runs expand option on the right side of the screen: \n - Look at the fmin_uuid for the hyperopt run\n - Search for relevant entries, for example tags.fmin_uuid = 'a75fb4'\n - Select all observations\n - Select 'Compare'\n - Select 'Parallel coordinates plot'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4751f4c9-25a6-4ec3-88b2-1c3395f11621"}}},{"cell_type":"markdown","source":["## Fin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a68b8f3-adc1-410d-8018-784d66d93b9c"}}},{"cell_type":"markdown","source":["## Extra: Distributed random forests with single threaded hyperopt\nInstead of running multiple models parallel, it is possible to run a single model parallelised by using MLlib's random forrest implementation. In this case HyperOpt will be run in non-distributed mode."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae826e00-181d-4ad3-bc1b-21edbe69253c"}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.mllib.tree import RandomForest\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n\nimport mlflow\n\nimport hyperopt as hp\nfrom hyperopt import fmin, rand, tpe, hp, Trials, exceptions, space_eval, STATUS_FAIL, STATUS_OK\nimport datetime"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"047442c6-7f32-4c43-b1c3-303aeea5c64c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Read data\nRead the train and test data. This data is already in a dataframe, and the features and label columns for MLlib have already been created."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a63a784-8c1f-4cb2-8076-b916fb1cc723"}}},{"cell_type":"code","source":["def read_data(path):\n  \"\"\"\n  This function read data data from s3 and drops columns that are not required for the modelling process\n  \n  :param path: the input path on dbfs \n  :return: a dataframe referencing the data on the input path\n  \"\"\"\n    \n  return spark.read.format(\"delta\")\\\n    .option(\"path\", path)\\\n    .load()\\\n    .select(\"features\", \"label\")\n\n\n\ntrain_df = read_data(train_data_path)\ntest_df = read_data(test_data_path) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7198c19a-5949-41c1-86d1-d08568a74bc1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["display(train_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22efa201-4494-4906-8469-ba0b66a3eb9e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Training function\nFor each set of parameters selected by HyperOpt a model will be fit. The return values constitue of the fitted model and the validation accuracy."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8903d2b-26e6-4236-a4ee-613977f99faf"}}},{"cell_type":"code","source":["def fit_model(params, training_df):\n  \"\"\"\n  This function fits a model given the params passed by HyperOpt.\n  \n  :param params: the params passed by HyperOpt. \n  :param training_df: the data to fit the model with. \n  :return: a fitted model.\n  \"\"\"\n    \n  # Get the HyperOpt settings\n  seed = params['seed']\n  num_trees = int(params['num_trees'])\n  min_instances_per_node = int(params['min_instances_per_node'])\n  impurity = params['impurity']\n\n  # Cache the training data in memory\n  training_df.cache()\n  n = training_df.count()\n\n  # Create and fit the random forest classifier\n  rf = RandomForestClassifier(labelCol=\"label\", \n                              featuresCol=\"features\", \n                              featureSubsetStrategy=\"sqrt\", \n                              numTrees=num_trees, \n                              minInstancesPerNode=min_instances_per_node,\n                              impurity=impurity,\n                              seed=seed)\n\n  pipeline = Pipeline(stages = [rf])\n  rf_model = pipeline.fit(training_df)\n  \n  return rf_model\n  \n  # Cleanup memory\n  training_df.unpersist()\n  \ndef train_mllib(params):\n  \"\"\"\n  This function trains a model given the params passed by HyperOpt.\n  \n  :param params: the params passed by HyperOpt. \n  :return: a model and the validation score.\n  \"\"\"\n\n  # Get the HyperOpt settings  \n  seed = params['seed']\n\n  # There is no support for out-of-bag evaluation\n  (training_df, validation_df) = train_df.randomSplit([0.8, 0.2], seed=seed)\n\n  # Fit a model to the training data\n  rf_model = fit_model(params, training_df)\n  \n  # Calculate validation score\n  predictions = rf_model.transform(validation_df)\n  \n  evaluator = MulticlassClassificationEvaluator(metricName='accuracy')\n  score = 1.0 - evaluator.evaluate(predictions)\n  \n  return rf_model, score"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4903f627-90c7-4299-8911-b78c1dcbb19c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def evaluate_mllib_hyperparams(params):\n  \"\"\"\n  This method will be passed to `hyperopt.fmin()`.  It fits and evaluates the model using the given hyperparameters to get the validation loss.\n  \n  :param params: This dict of parameters specifies hyperparameter values to test.\n  :return: dict with fields 'loss' (scalar loss) and 'status' (success/failure status of run)\n  \"\"\"\n  \n  # Train the model\n  model, score = train_mllib(params)\n        \n  return {'loss': score, 'status': STATUS_OK, 'model': model}\n\n# The hyper parameter space to search\nimpurities = ['gini', 'entropy']\n\nsearch_space = {\n  'seed': hp.randint('seed', 1000000),\n  'num_trees': hp.uniform('num_trees', 10, 500),\n  'min_instances_per_node': hp.uniform('min_instances_per_node', 1, 20),\n  'impurity': hp.choice('impurity', impurities)\n}\n\n# The algoritm to perform the parameter search\nalgo=tpe.suggest  # Tree of Parzen Estimators (a \"Bayesian\" method)\n#algo=random.suggest  # Random search\n\n# The results of the HyperOpt run will end up in the trials object\ntrials = Trials()\n\n# name the run\nnow = datetime.datetime.now()\nrun_name = now.strftime(\"%Y%m%d-%H%M\")\n\n# Execute the search with MLFlow support\nwith mlflow.start_run(run_name=run_name):\n  argmin = fmin(\n    fn=evaluate_mllib_hyperparams,\n    space=search_space,\n    algo=algo,\n    trials = trials,\n    max_evals=40)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"502b061f-b126-491a-b9d6-ab98131d8f08"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["argmin"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bae9817-caae-4b1e-a027-4955888e4341"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Recreate best model using the HyperOpt output"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49718612-3b7c-4bef-8cc9-f32b6861a09e"}}},{"cell_type":"code","source":["# Because HyperOpt was run locally, we could return the trained model \n# along with the loss and the status in evaluate_mllib_hyperparams.\n# Therefor we can now lookup the best model in the trials object\nmodel = trials.results[np.argmin([r['loss'] for r in trials.results])]['model']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72f6d246-5d23-4cf1-8c81-d34c8f194a66"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Since storing all the model of all the trials requires quite some memory, \n# an alternative would be to not return the model from evaluate_mllib_hyperparams.\n# In this case the model needs to be recreated.\nparams = {'impurity': 1,\n 'min_instances_per_node': 14.058068956915708,\n 'num_trees': 43.63883612231973,\n 'seed': 827362}\n\nparams['impurity'] = impurities[params['impurity']]\n\n# Consider using all the data with model = fit_model(params, train_df)\nmodel, score = train_mllib(params)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00a5b7dd-c2c2-436e-91e8-3a6af67cbc51"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Generate scores on the test data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"527f0931-5cf2-4aa0-80c5-630fa031f392"}}},{"cell_type":"code","source":["predictions = model.transform(test_df)\n\nevaluator = BinaryClassificationEvaluator(metricName='areaUnderROC')\nauc = evaluator.evaluate(predictions)\nprint(\"AUC score on test data: {}\".format(auc))\n  \n# MulticlassClassificationEvaluator supports the F1 score\nevaluator = MulticlassClassificationEvaluator()\nf1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\nprint(\"F1 score on test data: {}\".format(f1))\n\n# MulticlassClassificationEvaluator supports the F1 score\nevaluator = MulticlassClassificationEvaluator()\nacc = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\nprint(\"Accuracy score on test data: {}\".format(acc))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"878e6d3d-63c5-41a1-ba4c-6aa3bf2a2c70"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29a990f7-84ad-4c22-bde6-8e20a8fae14a"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"02 Random Forest Distributed HyperOpt","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3256439173735940}},"nbformat":4,"nbformat_minor":0}
