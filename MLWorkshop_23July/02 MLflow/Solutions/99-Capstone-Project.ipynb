{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bcdd77f-ae6b-467c-b20a-6d2d92e1e0c9"}}},{"cell_type":"markdown","source":["# Capstone Project: Managing the Machine Learning Lifecycle\n\nCreate a workflow that includes pre-processing logic, the optimal ML algorithm and hyperparameters, and post-processing logic.\n\n## Instructions\n\nIn this course, we've primarily used Random Forest in `sklearn` to model the Airbnb dataset.  In this exercise, perform the following tasks:\n<br><br>\n0. Create custom pre-processing logic to featurize the data\n0. Try a number of different algorithms and hyperparameters.  Choose the most performant solution\n0. Create related post-processing logic\n0. Package the results and execute it as its own run\n\n## Prerequisites\n- Web browser: Chrome\n- A cluster configured with **8 cores** and **DBR 7.0 ML**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f69c8d4f-da64-4590-a9e8-8af0946075b4"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the<br/>\nstart of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d574b1f2-ee1d-4b22-86aa-c61977cb5334"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"059093f8-531d-400f-9a1d-9a9babbb8e3a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Adust our working directory from what DBFS sees to what python actually sees\nworking_path = workingDir.replace(\"dbfs:\", \"/dbfs\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5448236-40a5-40d0-a8ee-0ad6e33969d2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Pre-processing\n\nTake a look at the dataset and notice that there are plenty of strings and `NaN` values present. Our end goal is to train a sklearn regression model to predict the price of an airbnb listing.\n\n\nBefore we can start training, we need to pre-process our data to be compatible with sklearn models by making all features purely numerical."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c0d57f0b-ef5e-445b-9c5a-36988b086f89"}}},{"cell_type":"code","source":["import pandas as pd\n\nairbnbDF = spark.read.parquet(\"/mnt/training/airbnb/sf-listings/sf-listings-correct-types.parquet\").toPandas()\n\ndisplay(airbnbDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"155cd8f7-09fc-4428-a747-9f8252aa345a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["In the following cells we will walk you through the most basic pre-processing step necessary. Feel free to add additional steps afterwards to improve your model performance."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7be37cf0-a5a1-4bae-8d1f-1e572235ee49"}}},{"cell_type":"markdown","source":["First, convert the `price` from a string to a float since the regression model will be predicting numerical values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b3f0aec-466b-4b00-9573-88653f22a049"}}},{"cell_type":"code","source":["# ANSWER\nairbnbDF[\"int_price\"] = airbnbDF[\"price\"].apply(lambda s: float(s.replace(\"$\", \"\").replace(\",\", \"\")))\nairbnbDF_cleaned_price = airbnbDF.drop([\"price\"],axis=1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e24b188-a396-4e91-95d4-086e07f92b47"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Take a look at our remaining columns with strings (or numbers) and decide if you would like to keep them as features or not.\n\nRemove the features you decide not to keep."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"839fb34b-c784-4c8a-90ca-21d7097a2ae7"}}},{"cell_type":"code","source":["# ANSWER\nairbnbDF_cleaned_features = airbnbDF_cleaned_price.drop([\"host_is_superhost\", \"instant_bookable\",\"cancellation_policy\"], axis=1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58ea1bb3-562a-4282-bc23-51d1410b8059"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["For the string columns that you've decided to keep, pick a numerical encoding for the string columns. Don't forget to deal with the `NaN` entries in those columns first."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea01ba99-5aa3-44c2-b7b9-655cbec53db9"}}},{"cell_type":"code","source":["# ANSWER\n\nairbnbDF_cleaned_features = airbnbDF_cleaned_features[airbnbDF_cleaned_features[\"zipcode\"] != \"-- default zip code --\"] # removed entry with unusual zipcode\nairbnbDF_cleaned_features = airbnbDF_cleaned_features.dropna(subset=[\"zipcode\"])\n\n# encoded each string label into an integer\nairbnbDF_cleaned_features['zipcode'] = pd.factorize(airbnbDF_cleaned_features['zipcode'])[0]\nairbnbDF_cleaned_features['neighbourhood_cleansed'] = pd.factorize(airbnbDF_cleaned_features['neighbourhood_cleansed'])[0]\nairbnbDF_cleaned_features['property_type'] = pd.factorize(airbnbDF_cleaned_features['property_type'])[0]\nairbnbDF_cleaned_features['room_type'] = pd.factorize(airbnbDF_cleaned_features['room_type'])[0]\nairbnbDF_cleaned_features['bed_type'] = pd.factorize(airbnbDF_cleaned_features['bed_type'])[0]\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"090c61dc-8167-4d21-9ae7-c0f1838d184f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Before we create a train test split, check that all your columns are numerical. Remember to drop the original string columns after creating numerical representations of them.\n\nMake sure to drop the price column from the training data when doing the train test split."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fbec1634-3689-4984-8603-ce28cefe5fcb"}}},{"cell_type":"code","source":["# ANSWER\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(airbnbDF_cleaned_features.drop([\"int_price\"], axis=1), airbnbDF_cleaned_features[[\"int_price\"]].values.ravel(), random_state=42)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e073bbfe-ebf5-4064-a1d1-4e0b9427ad28"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Model\n\nAfter cleaning our data, we can start creating our model!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"14222315-d62a-49be-a54c-d61fd631dcde"}}},{"cell_type":"markdown","source":["Firstly, if there are still `NaN`'s in your data, you may want to impute these values instead of dropping those entries entirely. Make sure that any further processing/imputing steps after the train test split is part of a model/pipeline that can be saved.\n\nIn the following cell, create and fit a single sklearn model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84acdaa6-58fc-4c0d-b94e-d099e4749d81"}}},{"cell_type":"code","source":["# ANSWER\n\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\n\n# impute NaN values of data with median\ncolumns_to_impute = [\"review_scores_value\", \"review_scores_location\", \"review_scores_rating\", \"review_scores_accuracy\", \"review_scores_cleanliness\", \"review_scores_checkin\", \"review_scores_communication\", \"host_total_listings_count\", \"bathrooms\", \"beds\"]\npreprocessing_steps = []\nfor col in columns_to_impute:\n  imp = SimpleImputer(missing_values=np.nan, strategy='median')\n  preprocessing_steps.append((col+\"Imputer\", imp))\n\n# define regression \nn_estimators=100\nmax_depth=5\nmodel = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth) \n\n# create and train pipeline\npipeline = Pipeline(preprocessing_steps+[(\"model\", model)])\npipeline.fit(X_train, y_train) \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03889429-d2b2-49b1-a87e-ef9e48e03dce"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Pick and calculate a regression metric for evaluating your model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9a31f17-7d0b-40ea-a99f-71c0cca1088e"}}},{"cell_type":"code","source":["# ANSWER\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\npipeline.predict(X_test)\n\nrmse = np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test)))\nrmse"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dac27634-4603-470f-86e7-aafdecdfbda3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Log your model on MLflow with the same metric you calculated above so we can compare all the different models you have tried! Make sure to also log any hyperparameters that you plan on tuning!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5308860f-7990-4c87-9553-6f5285f79a3a"}}},{"cell_type":"code","source":["# ANSWER\nimport mlflow.sklearn\n\nwith mlflow.start_run() as run:\n  mlflow.sklearn.log_model(pipeline, \"model\")\n  mlflow.log_param(\"max_depth\", max_depth)\n  mlflow.log_param(\"n_estimators\", n_estimators)\n  mlflow.log_metric(\"rmse\", rmse)\n\n  experimentID = run.info.experiment_id"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6cd419eb-9143-4983-a87c-41438a19fccf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Change and re-run the above 3 code cells to log different models and/or models with different hyperparameters until you are satisfied with the performance of at least 1 of them."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"61abcaba-7df0-4aba-a345-0ea89bab7a93"}}},{"cell_type":"markdown","source":["Look through the MLflow UI for the best model. Copy its `URI` so you can load it as a `pyfunc` model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fcb265a0-1464-4370-98ba-49b1530f9f1f"}}},{"cell_type":"code","source":["# ANSWER\nimport mlflow.pyfunc\nfrom mlflow.tracking import MlflowClient\nimport pandas as pd\nclient = MlflowClient()\n\nruns = []\nfor run in client.search_runs(experimentID):\n  run_dict = run.to_dictionary()\n  rmse = run_dict[\"data\"][\"metrics\"].get(\"rmse\")\n  artifact_uri = run_dict[\"info\"].get(\"artifact_uri\")\n  if rmse:\n    runs.append((rmse, artifact_uri))\n  \nrunsDF = pd.DataFrame(runs, columns = [\"rmse\", \"artifact_uri\"])\nbest_URI = runsDF.sort_values(\"rmse\").iloc[0,-1]\n\nbest_model_path = best_URI.replace(\"dbfs:\", \"/dbfs\") + \"/model\"\nbest_model = mlflow.pyfunc.load_model(model_uri=best_model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f867a9b1-2ff3-4aa2-a025-5398d90dfe8a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Post-processing\n\nOur model currently gives us the predicted price per night for each Airbnb listing. Now we would like our model to tell us what the price per person would be for each listing, assuming the number of renters is equal to the `accommodates` value."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c44da034-9cc6-43ff-8e79-3798091e3b16"}}},{"cell_type":"markdown","source":["-sandbox\nFill in the following model class to add in a post-processing step which will get us from total price per night to **price per person per night**.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Check out <a href=\"https://www.mlflow.org/docs/latest/models.html#id13\" target=\"_blank\">the MLFlow docs for help.</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"944bbfcc-5a2a-400d-ad81-79ca40b42417"}}},{"cell_type":"code","source":["# ANSWER\nclass Airbnb_Model(mlflow.pyfunc.PythonModel):\n\n    def __init__(self, model):\n        self.model = model\n\n    def postprocess_result(self, model_input, results):\n        return results/list(model_input[\"accommodates\"])\n    \n    def predict(self, context, model_input):\n        results = self.model.predict(model_input)\n        return self.postprocess_result(model_input, results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c08675d7-431d-4124-bb81-74b747731e09"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Construct and save the model to the given `final_model_path`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"afa50235-6af5-4333-97ae-b28654512e45"}}},{"cell_type":"code","source":["# ANSWER\nfinal_model_path =  f\"{working_path}/model\"\n\nimport shutil # just in case\ntry: shutil.rmtree(final_model_path)\nexcept: pass # ignore any errors\n\nprice_per_person = Airbnb_Model(best_model)\nmlflow.pyfunc.save_model(path=final_model_path, python_model=price_per_person)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97bc52fa-f6f3-4172-bb5e-f2e129e0053a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Load the model in `python_function` format and apply it to our test data `X_test` to check that we are getting price per person predictions now."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1115cfe5-3828-486a-a02f-d02c6a064eca"}}},{"cell_type":"code","source":["# ANSWER\n# Load the model\nfinal_model = mlflow.pyfunc.load_model(final_model_path)\n\n# Apply the model\nfinal_model.predict(X_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"229e59c2-ce78-4d6a-af4e-6fc2beddc19a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Packaging your Model\n\nNow we would like to package our completed model!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b8a6271-249b-446c-9890-0d79a119d433"}}},{"cell_type":"markdown","source":["-sandbox\nFirst save your testing data at `test_data_path` so we can test the packaged model.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** When using `.to_csv` make sure to set `index=False` so you don't end up with an extra index column in your saved dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77f6b2be-4e61-4611-8abb-f705d91ec0aa"}}},{"cell_type":"code","source":["# ANSWER\n# save the testing data \ntest_data_path = f\"{working_path}/test_data.csv\"\nX_test.to_csv(test_data_path, index=False)\n\nprediction_path = f\"{working_path}/predictions.csv\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73b140f9-b957-4ffb-936e-e42d985559c3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["First we will determine what the project script should do. Fill out the `model_predict` function to load out the trained model you just saved (at `final_model_path`) and make price per person predictions on the data at `test_data_path`. Then those predictions should be saved under `prediction_path` for the user to access later.\n\nRun the cell to check that your function is behaving correctly and that you have predictions saved at `demo_prediction_path`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3202409c-ba72-4711-8ffa-c398112f2429"}}},{"cell_type":"code","source":["# ANSWER\nimport click\nimport mlflow.pyfunc\nimport pandas as pd\n\n@click.command()\n@click.option(\"--final_model_path\", default=\"\", type=str)\n@click.option(\"--test_data_path\", default=\"\", type=str)\n@click.option(\"--prediction_path\", default=\"\", type=str)\ndef model_predict(final_model_path, test_data_path, prediction_path):\n  final_model = mlflow.pyfunc.load_model(final_model_path)\n  X_test = pd.read_csv(test_data_path)\n  prediction = final_model.predict(X_test) \n  pd.DataFrame(prediction).to_csv(prediction_path, index=False)\n\n# test model_predict function\ndemo_prediction_path = f\"{working_path}/predictions.csv\"\n\nfrom click.testing import CliRunner\nrunner = CliRunner()\nresult = runner.invoke(model_predict, ['--final_model_path', final_model_path, \n                                       '--test_data_path', test_data_path,\n                                       '--prediction_path', demo_prediction_path], catch_exceptions=True)\n\nassert result.exit_code == 0, \"Code failed\" # Check to see that it worked\nprint(\"Price per person predictions: \")\nprint(pd.read_csv(demo_prediction_path))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb375e7b-b4ea-405b-b8df-e7d06a91d02c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Next, we will create a MLproject file and put it under our `workingDir`. Complete the parameters and command of the file."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6bc45e32-7adc-4861-b8e1-6908557a5468"}}},{"cell_type":"code","source":["# ANSWER\ndbutils.fs.put(f\"{workingDir}/MLproject\", \n'''\nname: Capstone-Project\n\nconda_env: conda.yaml\n\nentry_points:\n  main:\n    parameters:\n      final_model_path: {type: str, default: \"\"}\n      test_data_path: {type: str, default: \"\"}\n      prediction_path: {type: str, default: \"\"}\n      stacktrace_path: {type: str, default: \"\"}\n    command: \"python predict.py --test_data_path {test_data_path} --final_model_path {final_model_path} --prediction_path {prediction_path} --stacktrace_path {stacktrace_path}\"\n'''.strip(), overwrite=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4027b8b-9740-4c1d-ad8a-f218a40bade6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(prediction_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed585afd-b793-4a7c-b5ad-95ceabf2e9fa"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We then create a `conda.yaml` file to list the dependencies needed to run our script.\n\nFor simplicity, we will ensure we use the same version as we are running in this notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f490f2b4-5256-4492-8a03-c9406d12eda5"}}},{"cell_type":"code","source":["import cloudpickle, numpy, pandas, sklearn, sys\n\nversion = sys.version_info # Handles possibly conflicting Python versions\n\nfile_contents = f\"\"\"\nname: Capstone\nchannels:\n  - defaults\ndependencies:\n  - python={version.major}.{version.minor}.{version.micro}\n  - cloudpickle={cloudpickle.__version__}\n  - numpy={numpy.__version__}\n  - pandas={pandas.__version__}\n  - scikit-learn={sklearn.__version__}\n  - pip:\n    - mlflow=={mlflow.__version__}\n\"\"\".strip()\n\ndbutils.fs.put(f\"{workingDir}/conda.yaml\", file_contents, overwrite=True)\n\nprint(file_contents)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2f6f7a4-c068-4c1c-b1bd-c9bba31d20a0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now we will put the **`predict.py`** script into our project package.\n\nComplete the **`.py`** file by copying and placing the **`model_predict`** function you defined above."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8237ac5-0b09-408a-b3c9-68c02b4bf032"}}},{"cell_type":"code","source":["# ANSWER\ndbutils.fs.put(f\"{workingDir}/predict.py\", \n'''\nimport click\nimport mlflow.pyfunc\nimport pandas as pd\nimport traceback\n\n@click.command()\n@click.option(\"--final_model_path\", default=\"\", type=str)\n@click.option(\"--test_data_path\", default=\"\", type=str)\n@click.option(\"--prediction_path\", default=\"\", type=str)\n@click.option(\"--stacktrace_path\", default=\"\", type=str)\ndef model_predict(final_model_path, test_data_path, prediction_path, stacktrace_path):\n  try:\n    final_model = mlflow.pyfunc.load_model(final_model_path)\n    X_test = pd.read_csv(test_data_path)\n    prediction = final_model.predict(X_test) \n    pd.DataFrame(prediction).to_csv(prediction_path, index = False)\n    \n  except:\n    file = open(stacktrace_path, \"w\")\n    traceback.print_exc(file=file)\n    file.close()\n    \nif __name__ == \"__main__\":\n  model_predict()\n\n'''.strip(), overwrite=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97d661c6-e9f7-47ae-9c4a-75209b0c18b9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's double check all the files we've created are in the `workingDir` folder. You should have at least the following 3 files:\n* `MLproject`\n* `conda.yaml`\n* `predict.py`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fbe5dde7-62af-4032-bde7-7aadcc9794c6"}}},{"cell_type":"code","source":["display( dbutils.fs.ls(workingDir) )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78349931-d38c-4306-9312-318df7b3d238"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Under **`workingDir`** is your completely packaged project.\n\nRun the project to use the model saved at **`final_model_path`** to predict the price per person of each Airbnb listing in **`test_data_path`** and save those predictions under **`second_prediction_path`** (defined below)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"411b33c0-dac5-4922-9565-5f7b90832a2a"}}},{"cell_type":"code","source":["# ANSWER\n\nsecond_prediction_path = f\"{working_path}/predictions-2.csv\"\n\nmlflow.projects.run(working_path,\n  parameters={\n    \"final_model_path\": final_model_path,\n    \"test_data_path\": test_data_path,\n    \"prediction_path\": second_prediction_path,\n    \"stacktrace_path\": f\"{working_path}/stacktrace.txt\"\n})\n\ntry: print( dbutils.fs.head(f\"{workingDir}/stacktrace.txt\") )\nexcept: print(\"No errors detected\") # No file, then no error"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42ef70a7-501d-4afb-bbbc-30adc0344243"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Run the following cell to check that your model's predictions are there!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3c68ea6-b687-405a-8b58-d779736b429d"}}},{"cell_type":"code","source":["print(\"Price per person predictions: \")\nprint(pd.read_csv(second_prediction_path))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9c91d07-a302-4f07-b002-b2e64583654e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4db482cd-253d-49d1-b535-0367724a707a"}}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Cleanup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e478808a-77fd-48f2-a51b-fbee06a0ff3a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> All done!</h2>\n\nThank you for your participation!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4f1cea5-dbab-4d1d-a791-122d4f725fd4"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"840507e4-c6cb-40ae-ae8a-d47e7dffeebd"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"99-Capstone-Project","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3256439173736576}},"nbformat":4,"nbformat_minor":0}
