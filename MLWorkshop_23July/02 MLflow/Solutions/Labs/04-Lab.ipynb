{"cells":[{"cell_type":"markdown","source":["# Lab: Adding Pre and Post-Processing Logic\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you:<br>\n - Import data and train a random forest model\n - Defining pre-processing steps\n - Adding post-processing steps\n \n## Prerequisites\n- Web browser: Chrome\n- A cluster configured with **8 cores** and **DBR 7.3 ML**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24599346-ec75-4df7-93cb-4538beaa7377"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the<br/>\nstart of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74d28d5b-412d-4f3b-a6dd-a459645735a2"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a561fc94-923e-41db-a9d8-5da121ba1e62"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Import Data and Train Random Forest"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22a3270c-7d4b-45c6-9435-10af97e27767"}}},{"cell_type":"markdown","source":["Import the Airbnb DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9492826c-1b9e-4b5a-baf4-a3b7ac806b0d"}}},{"cell_type":"code","source":["import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"/dbfs/mnt/training/airbnb/sf-listings/airbnb-cleaned-mlflow.csv\")\nX_train, X_test, y_train, y_test = train_test_split(df.drop([\"price\"], axis=1), df[[\"price\"]].values.ravel(), random_state=42)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a648312a-8e6c-4c91-95b6-a902951af6ad"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Train a random forest model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"57762683-9099-428f-854b-b3202d18df9f"}}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nrf = RandomForestRegressor(n_estimators=100, max_depth=25)\nrf.fit(X_train, y_train)\nrf_mse = mean_squared_error(y_test, rf.predict(X_test))\n\nrf_mse"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d88b1861-559b-43f0-b9c3-d4c379e4bc43"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Pre-processing Our Data\n\nWe would like to add some pre-processing steps to our data before training a RF model in order to decrease the MSE and improve our model's performance.\n\nTake a look at the first 10 rows of our data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1adda86b-21c2-428e-a7f7-cf68812f5042"}}},{"cell_type":"code","source":["df.iloc[:10]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35bddb79-0eb6-430c-a3c4-4fe534e428ec"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\nNotice that all the values in the `latitude` and `longitude` columns are very similar (up to tenth place) since all the Airbnb listings are in San Francisco. The Airbnb pricing probably will not vary too much between longitude and latitude differences of 0.0001 so we can facilitate the splitting factors of our tree by rounding the `latitude` and `longitude` values to the nearest hundredth instead of worrying about all 6 digits after the decimal point. We will create these values in new columns called `trunc_lat` and `trunc_long` and drop the original `latitude` and `longitude` columns.\n\nAdditionally, notice that the 'review_scores_accuracy',\n       'review_scores_cleanliness', 'review_scores_checkin',\n       'review_scores_communication', 'review_scores_location', and\n       'review_scores_value'\n       encode pretty similar information so we will go ahead and summarize them into single column called `summed_review_scores` which contains the summation of the above 6 columns. Hopefully the tree will be able to make a more informed split given this additional information.\n\n\nFill in the pre-processing lines to create the `X_test_processed` and `X_train_processed` DataFrames. Then we will train a new random forest model off this pre-processed data.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Take a look at python's built in `round` function."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ef8f8f8-5f6e-4124-ad01-429353b8db0c"}}},{"cell_type":"code","source":["# ANSWER\n# new random forest model\nrf2 = RandomForestRegressor(n_estimators=100, max_depth=25)\n\ncols_to_drop = [\"latitude\", \"longitude\"]\n\nX_train_processed = X_train.copy()\nX_train_processed[\"trunc_lat\"] = round(X_train[\"latitude\"], 3)\nX_train_processed[\"trunc_long\"] = round(X_train[\"longitude\"], 3)\nX_train_processed[\"review_scores_sum\"] = (\n   X_train['review_scores_accuracy'] + \n   X_train['review_scores_cleanliness']+\n   X_train['review_scores_checkin'] + \n   X_train['review_scores_communication'] + \n   X_train['review_scores_location'] + \n   X_train['review_scores_value']\n)\nX_train_processed = X_train_processed.drop(cols_to_drop, axis=1)\n\n\nX_test_processed = X_test.copy()\nX_test_processed[\"trunc_lat\"] = round(X_test[\"latitude\"], 3)  \nX_test_processed[\"trunc_long\"] = round(X_test[\"longitude\"], 3) \nX_test_processed[\"review_scores_sum\"] = (\n  X_test['review_scores_accuracy'] +\n  X_test['review_scores_cleanliness'] +\n  X_test['review_scores_checkin'] + \n  X_test['review_scores_communication'] +\n  X_test['review_scores_location'] +\n  X_test['review_scores_value']\n)\nX_test_processed = X_test_processed.drop(cols_to_drop, axis=1)\n\n\n# fit and evaluate new rf model\nrf2.fit(X_train_processed, y_train)\nrf2_mse = mean_squared_error(y_test, rf2.predict(X_test_processed))\n\nrf2_mse"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f06e653-5f36-4920-b86e-be368b4c9e82"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["After training our new `rf2` model, let us log this run in MLflow so we can use this trained model in the future by loading it."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35f87211-f79d-4c93-830e-25551ddf033c"}}},{"cell_type":"code","source":["import mlflow.sklearn\n\nwith mlflow.start_run(run_name=\"RF Model Pre-process\") as run: \n  mlflow.sklearn.log_model(rf2, \"random-forest-model-preprocess\")\n  mlflow.log_metric(\"mse\", rf2_mse)\n  \n  experimentID = run.info.experiment_id\n  artifactURI = mlflow.get_artifact_uri()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9ee5cdf-362d-44c7-8f56-250cdac83ebe"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now let's load the `python_function` flavor of the model so we can apply it to a test set."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42521348-2724-47dd-8b6d-60f4781475fb"}}},{"cell_type":"code","source":["import mlflow.pyfunc\nfrom  mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\nrf2_run = sorted(client.list_run_infos(experimentID), key=lambda r: r.start_time, reverse=True)[0]\nrf2_path = rf2_run.artifact_uri+\"/random-forest-model-preprocess/\"\n\nrf2_pyfunc_model = mlflow.pyfunc.load_model(rf2_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c6e961e-b44e-46e3-ab46-544996916ecb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's try giving our new `rf2_pyfunc_model` the `X_test` DataFrame to generate predictions off of."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70731897-9616-47f4-aa41-1e37a81094f9"}}},{"cell_type":"code","source":["try:\n  rf2_pyfunc_model.predict(X_test)\nexcept ValueError as e:\n  print(\"ERROR: \" + str(e))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66edee0b-545b-4ae6-80b3-b038405d57ed"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Why did this fail?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad570e9b-88a2-404f-8f9e-e9ed7f183c54"}}},{"cell_type":"markdown","source":["## Adding Pre-Processing Steps\n\nWe trained our `rf2` model using a pre-processed training set that has one extra column (`review_scores_sum`) than the unprocessed `X_train` and `X_test` DataFrames.  The `rf2` model is expecting to have `review_scores_sum` as an input column as well. Even if `X_test` had the same number of columns as the processed data we trained on, the line above will still error since it does not have our custom truncated `trunc_lat` and `trunc_long` columns.\n\nTo fix this, we could manually re-apply the same pre-processing logic to the `X_test` set each time we wish to use our model. \n\nHowever, there is a cleaner and more streamlined way to account for our pre-processing steps. We can define a custom model class that automatically pre-processes the raw input it receives before passing that input into the trained model's `.predict()` function. This way, in future applications of our model, we will no longer have to worry about remembering to pre-process every batch of data beforehand.\n\nComplete the `preprocess_input(self, model_input)` helper function of the custom `RF_with_preprocess` class so that the random forest model is always predicting off of a DataFrame with the correct column names and the appropriate number of columns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f61edbc-5512-44b4-a024-c731f0bbb8d2"}}},{"cell_type":"code","source":["# ANSWER\n# Define the model class\nclass RF_with_preprocess(mlflow.pyfunc.PythonModel):\n\n    def __init__(self, trained_rf):\n        self.rf = trained_rf\n\n    def preprocess_input(self, model_input):\n        '''return pre-processed model_input'''\n        model_input[\"trunc_lat\"] = round(model_input[\"latitude\"], 3)\n        model_input[\"trunc_long\"] = round(model_input[\"longitude\"], 3)\n        model_input[\"review_scores_sum\"] = ( \n          model_input['review_scores_accuracy'] +\n          model_input['review_scores_cleanliness'] +\n          model_input['review_scores_checkin'] +\n          model_input['review_scores_communication'] +\n          model_input['review_scores_location'] +\n          model_input['review_scores_value']\n        )\n        model_input = model_input.drop([\"latitude\", \"longitude\"], axis=1)\n        return model_input\n    \n    def predict(self, context, model_input):\n        processed_model_input = self.preprocess_input(model_input.copy())\n        return self.rf.predict(processed_model_input)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a635597-996e-4144-b7d5-feb040c8b0b2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's save, then load this custom model's `python_function`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb2d0f45-c485-4fed-b4fc-2730f9d7fca0"}}},{"cell_type":"code","source":["import shutil\n\n# Construct and save the model\nmodel_path =  f\"{workingDir}/RF_with_preprocess/\".replace(\"dbfs:\", \"/dbfs\")\nshutil.rmtree(model_path, True) # remove folder if already exists\n\nrf_preprocess_model = RF_with_preprocess(trained_rf = rf2)\nmlflow.pyfunc.save_model(path=model_path, python_model=rf_preprocess_model)\n\n# Load the model in `python_function` format\nloaded_preprocess_model = mlflow.pyfunc.load_model(model_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc7016ef-eceb-4cfd-87a8-4d0c5bb7f7d1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now we can directly give our loaded model the unmodified `X_test` and have it generate predictions without errors!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e73a278e-c539-405c-8f59-c011dfb4fd21"}}},{"cell_type":"code","source":["# Apply the model\nloaded_preprocess_model.predict(X_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"851abbed-7864-4b61-8f44-535f51701761"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Adding Post-Processing Steps\n\nNow suppose we are not as interested in a numerical prediction as we are in a categorical label of `Expensive` and `Not Expensive` where the cut-off is above a price of $100. Instead of retraining an entirely new classification model, we can simply add on a post-processing step to our custom model so it returns the predicted label instead of numerical price.\n\nComplete the following model class with **both the previous preprocess steps and the new `postprocess_result(self, result)`** function such that passing in `X_test` into our model will return an `Expensive` or `Not Expensive` label for each row."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"087cdd2e-8b19-413d-a672-fe49c74e155e"}}},{"cell_type":"code","source":["# ANSWER\n# Define the model class\nclass RF_with_postprocess(mlflow.pyfunc.PythonModel):\n\n    def __init__(self, trained_rf):\n        self.rf = trained_rf\n\n    def preprocess_input(self, model_input):\n        '''return pre-processed model_input'''\n        model_input[\"trunc_lat\"] = round(model_input[\"latitude\"], 3)\n        model_input[\"trunc_long\"] = round(model_input[\"longitude\"], 3)\n        model_input[\"review_scores_sum\"] = ( \n          model_input['review_scores_accuracy'] +\n          model_input['review_scores_cleanliness'] +\n          model_input['review_scores_checkin'] +\n          model_input['review_scores_communication'] +\n          model_input['review_scores_location'] +\n          model_input['review_scores_value']\n        )\n        model_input = model_input.drop([\"latitude\", \"longitude\"], axis=1)\n        return model_input\n      \n    def postprocess_result(self, results):\n        '''return post-processed results\n        Expensive: predicted price > 100\n        Not Expensive: predicted price <= 100'''\n        \n        return [\"Expensive\" if result>100 else \"Not Expensive\" for result in results]\n    \n    def predict(self, context, model_input):\n        processed_model_input = self.preprocess_input(model_input.copy())\n        results = self.rf.predict(processed_model_input)\n        return self.postprocess_result(results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3222ac0d-cc0d-479e-811f-d965d39dc166"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Create, save, and apply the model to `X_test`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b91f33b-4826-43ce-96c6-0b4fe443c33a"}}},{"cell_type":"code","source":["# Construct and save the model\nmodel_path =  f\"{workingDir}/RF_with_postprocess/\".replace(\"dbfs:\", \"/dbfs\")\n\nshutil.rmtree(model_path, True) # remove folder if already exists\n\nrf_postprocess_model = RF_with_postprocess(trained_rf = rf2)\nmlflow.pyfunc.save_model(path=model_path, python_model=rf_postprocess_model)\n\n# Load the model in `python_function` format\nloaded_postprocess_model = mlflow.pyfunc.load_model(model_path)\n\n# Apply the model\nloaded_postprocess_model.predict(X_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d7bcf3c-1658-4fdd-bcd0-eec9667b4388"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\nGiven any unmodified raw data, our model can perform the pre-processing steps, apply the trained model, and follow the post-processing step all in one `.predict` function call!\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> See the solutions folder for an example solution to this lab."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0589f9f0-4fc9-4ed3-88a8-245cb5c267b9"}}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b644bd1f-3dc9-44be-9117-07b2aac7a1fc"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Cleanup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa347d90-d0e2-4b6e-96ae-ae54789b4573"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["<h2><img src=\"https://files.training.databricks.com/images/105/logo_spark_tiny.png\"> All done!</h2>\n\nThank you for your participation!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd4a8043-e443-4f2c-8aa0-3e2068c5c241"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d70bc59-532f-4c82-aee7-41e62117fced"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"04-Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3256439173736500}},"nbformat":4,"nbformat_minor":0}
