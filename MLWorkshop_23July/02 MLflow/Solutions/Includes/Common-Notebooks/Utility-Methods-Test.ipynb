{"cells":[{"cell_type":"code","source":["spark.conf.set(\"com.databricks.training.module-name\", \"common-notebooks\")\n\ncourseAdvertisements = dict()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e37feba-8020-4d7e-9a40-cd5c2b8924e3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run ./Utility-Methods"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68899120-d4c8-4d6c-b48b-94c2bf1c6fd6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pythonTests = []\ndef functionPassed(result):\n  if result:\n    pythonTests.append(True)\n  else:\n    pythonTests.append(False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94afbf9b-0102-4e11-afab-d049b448d05d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `printRecordsPerPartition`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a2b7fa5e-9442-40b6-b4b3-73181f33f75c"}}},{"cell_type":"code","source":["def testPrintRecordsPerPartition():\n  \n    # Import data\n    peopleDF = spark.read.parquet(\"/mnt/training/dataframes/people-10m.parquet\")\n    \n    # Get printed results\n    import io\n    from contextlib import redirect_stdout\n\n    f = io.StringIO()\n    with redirect_stdout(f):\n        printRecordsPerPartition(peopleDF)\n    out = f.getvalue()\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct number of partitions are printing\n    testsPassed.append(None)\n    try:\n        assert int(out[out.rfind('#') + 1]) == peopleDF.rdd.getNumPartitions()\n        passedTest(True)\n    except:\n        passedTest(False, \"The correct number of partitions were not identified for printRecordsPerPartition\")\n        \n    # Test if each printed partition has a record number associated\n    testsPassed.append(None)\n    try:\n        output_list = [\n          {val.split(\" \")[0].replace(\"#\", \"\").replace(\":\", \"\"): int(val.split(\" \")[1].replace(\",\", \"\"))} \n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ]\n        assert all([isinstance(x[list(x.keys())[0]], int) for x in output_list])\n        passedTest(True)\n    except:\n        passedTest(False, \"Not every partition has an associated record count\")\n        \n    # Test if the sum of the printed number of records per partition equals the total number of records\n    testsPassed.append(None)\n    try:\n        printedSum = sum([\n          int(val.split(\" \")[1].replace(\",\", \"\"))\n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ])\n      \n        assert printedSum == peopleDF.count()\n        passedTest(True)\n    except:\n        passedTest(False, \"The sum of the number of records per partition does not match the total number of records\")\n    \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for printRecordsPerPartition passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for printRecordsPerPartition passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testPrintRecordsPerPartition()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c6657f6-c076-4ff2-a9db-c0c768ba5869"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `computeFileStats`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64d7c907-46c6-480b-bbbc-a6078389e019"}}},{"cell_type":"code","source":["def testComputeFileStats():\n  \n    # Set file path\n    filePath = \"/mnt/training/global-sales/transactions/2017.parquet\"\n  \n    # Run and get output\n    output = computeFileStats(filePath)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 2\n        assert isinstance(output[0], int)\n        assert isinstance(output[1], int)\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect structure is returned for computeFileStats\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0] == 6276\n        assert output[1] == 1269333224\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect result is returned for computeFileStats\")\n        \n    # Test that nonexistent file path throws error\n    testsPassed.append(None)\n    try:\n        computeFileStats(\"alkshdahdnoinscoinwincwinecw/cw/cw/cd/c/wcdwdfobnwef\")\n        passedTest(False, \"A nonexistent file path did not throw an error for computeFileStats\")\n    except:\n        passedTest(True)\n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for computeFileStats passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for computeFileStats passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testComputeFileStats()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96ba8695-a04a-43eb-a597-e816d3401253"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `cacheAs`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ad3376b-1a9b-480a-8e5b-96eed5606dd3"}}},{"cell_type":"code","source":["def testCacheAs():\n  \n    # Import DF\n    inputDF = spark.read.parquet(\"/mnt/training/global-sales/transactions/2017.parquet\").limit(100)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test uncached table gets cached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Uncached table was not cached for cacheAs\")\n        \n    # Test cached table gets recached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Cached table was not recached for cacheAs\")\n        \n    # Test wrong level still gets cached\n    testsPassed.append(None)\n    try:\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        cacheAs(inputDF, \"testCacheTable12344321\", \"WRONG_LEVEL\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Invalid storage level stopping caching for cacheAs\")\n        \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for cacheAs passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for cacheAs passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testCacheAs()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c96041b0-86aa-4fa2-9842-24ff697bb379"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `benchmarkCount()`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9cf905c3-2c44-492b-bb5c-5f9e971f6990"}}},{"cell_type":"code","source":["def testBenchmarkCount():\n  \n    from pyspark.sql import DataFrame\n    def testFunction():\n      return spark.createDataFrame([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n    output = benchmarkCount(testFunction)\n \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test that correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 3\n        assert isinstance(output[0], DataFrame)\n        assert isinstance(output[1], int)\n        assert isinstance(output[2], float)\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0].rdd.collect() == testFunction().rdd.collect()\n        assert output[1] == testFunction().count()\n        assert output[2] > 0 and output[2] < 10000\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")    \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for benchmarkCount passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for benchmarkCount passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testBenchmarkCount()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ee916ca-1398-498c-b30b-257272c073de"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test **`untilStreamIsReady()`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35a16c9c-57a8-4165-9778-683b48c732fd"}}},{"cell_type":"code","source":["dataPath = \"dbfs:/mnt/training/definitive-guide/data/activity-data-stream.json\"\ndataSchema = \"Recorded_At timestamp, Device string, Index long, Model string, User string, _corrupt_record String, gt string, x double, y double, z double\"\n\ninitialDF = (spark\n  .readStream                            # Returns DataStreamReader\n  .option(\"maxFilesPerTrigger\", 1)       # Force processing of only 1 file per trigger \n  .schema(dataSchema)                    # Required for all streaming DataFrames\n  .json(dataPath)                        # The stream's source directory and file type\n)\n\nname = \"Testing_123\"\n\ndisplay(initialDF, streamName = name)\nuntilStreamIsReady(name)\nassert len(spark.streams.active) == 1, \"Expected 1 active stream, found \" + str(len(spark.streams.active))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74b8aa32-95ed-47d0-b951-2c2fccbc2d26"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for stream in spark.streams.active:\n  stream.stop()\n  queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  while (len(queries) > 0):\n    time.sleep(5) # Give it a couple of seconds\n    queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  print(\"\"\"The stream \"{}\" has been terminated.\"\"\".format(stream.name))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"18e95058-8f37-4fca-8c8d-fe3e18254a71"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if all(pythonTests):\n    print('All {} tests for Python passed'.format(len(pythonTests)))\nelse:\n    print('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n    raise Exception('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e7b5b36-9bbb-4e69-a081-41bd2cac22c3"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Utility-Methods-Test","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3256439173736661}},"nbformat":4,"nbformat_minor":0}
