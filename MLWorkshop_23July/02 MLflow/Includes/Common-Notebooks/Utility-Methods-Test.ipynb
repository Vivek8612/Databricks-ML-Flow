{"cells":[{"cell_type":"code","source":["spark.conf.set(\"com.databricks.training.module-name\", \"common-notebooks\")\n\ncourseAdvertisements = dict()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4f0e4ed-7aa2-430a-86f9-7b0bd8e5ab99"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run ./Utility-Methods"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a43a459-077e-4bb8-bd79-dd46fe8df553"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pythonTests = []\ndef functionPassed(result):\n  if result:\n    pythonTests.append(True)\n  else:\n    pythonTests.append(False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"08718a47-8dc6-4e6e-9787-cdeebfeae93d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `printRecordsPerPartition`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3500bab0-b546-484c-bd27-73b2794475e6"}}},{"cell_type":"code","source":["def testPrintRecordsPerPartition():\n  \n    # Import data\n    peopleDF = spark.read.parquet(\"/mnt/training/dataframes/people-10m.parquet\")\n    \n    # Get printed results\n    import io\n    from contextlib import redirect_stdout\n\n    f = io.StringIO()\n    with redirect_stdout(f):\n        printRecordsPerPartition(peopleDF)\n    out = f.getvalue()\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct number of partitions are printing\n    testsPassed.append(None)\n    try:\n        assert int(out[out.rfind('#') + 1]) == peopleDF.rdd.getNumPartitions()\n        passedTest(True)\n    except:\n        passedTest(False, \"The correct number of partitions were not identified for printRecordsPerPartition\")\n        \n    # Test if each printed partition has a record number associated\n    testsPassed.append(None)\n    try:\n        output_list = [\n          {val.split(\" \")[0].replace(\"#\", \"\").replace(\":\", \"\"): int(val.split(\" \")[1].replace(\",\", \"\"))} \n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ]\n        assert all([isinstance(x[list(x.keys())[0]], int) for x in output_list])\n        passedTest(True)\n    except:\n        passedTest(False, \"Not every partition has an associated record count\")\n        \n    # Test if the sum of the printed number of records per partition equals the total number of records\n    testsPassed.append(None)\n    try:\n        printedSum = sum([\n          int(val.split(\" \")[1].replace(\",\", \"\"))\n          for val in out.split(\"\\n\") if val and val[0] == \"#\"\n        ])\n      \n        assert printedSum == peopleDF.count()\n        passedTest(True)\n    except:\n        passedTest(False, \"The sum of the number of records per partition does not match the total number of records\")\n    \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for printRecordsPerPartition passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for printRecordsPerPartition passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testPrintRecordsPerPartition()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72c690ac-88cb-4105-b0cf-d3d6e39eb3f6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `computeFileStats`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c279140-23a9-4293-97f4-86498a71a0db"}}},{"cell_type":"code","source":["def testComputeFileStats():\n  \n    # Set file path\n    filePath = \"/mnt/training/global-sales/transactions/2017.parquet\"\n  \n    # Run and get output\n    output = computeFileStats(filePath)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test if correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 2\n        assert isinstance(output[0], int)\n        assert isinstance(output[1], int)\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect structure is returned for computeFileStats\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0] == 6276\n        assert output[1] == 1269333224\n        passedTest(True)\n    except:\n        passedTest(False, \"The incorrect result is returned for computeFileStats\")\n        \n    # Test that nonexistent file path throws error\n    testsPassed.append(None)\n    try:\n        computeFileStats(\"alkshdahdnoinscoinwincwinecw/cw/cw/cd/c/wcdwdfobnwef\")\n        passedTest(False, \"A nonexistent file path did not throw an error for computeFileStats\")\n    except:\n        passedTest(True)\n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for computeFileStats passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for computeFileStats passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testComputeFileStats()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"799f3771-8a10-43ff-8134-0613ea10d589"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `cacheAs`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea45feab-955d-4722-aab1-ce91ae40cebc"}}},{"cell_type":"code","source":["def testCacheAs():\n  \n    # Import DF\n    inputDF = spark.read.parquet(\"/mnt/training/global-sales/transactions/2017.parquet\").limit(100)\n  \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test uncached table gets cached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Uncached table was not cached for cacheAs\")\n        \n    # Test cached table gets recached\n    testsPassed.append(None)\n    try:\n        cacheAs(inputDF, \"testCacheTable12344321\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Cached table was not recached for cacheAs\")\n        \n    # Test wrong level still gets cached\n    testsPassed.append(None)\n    try:\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        cacheAs(inputDF, \"testCacheTable12344321\", \"WRONG_LEVEL\")\n        assert spark.catalog.isCached(\"testCacheTable12344321\")\n        spark.catalog.uncacheTable(\"testCacheTable12344321\")\n        passedTest(True)\n    except:\n        passedTest(False, \"Invalid storage level stopping caching for cacheAs\")\n        \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for cacheAs passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for cacheAs passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testCacheAs()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dff84e2a-898d-480c-b308-ece50de31d88"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test `benchmarkCount()`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89fb027c-8250-46b3-9f7d-7c45422d9397"}}},{"cell_type":"code","source":["def testBenchmarkCount():\n  \n    from pyspark.sql import DataFrame\n    def testFunction():\n      return spark.createDataFrame([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n    output = benchmarkCount(testFunction)\n \n    # Setup tests\n    testsPassed = []\n    \n    def passedTest(result, message = None):\n        if result:\n            testsPassed[len(testsPassed) - 1] = True\n        else:\n            testsPassed[len(testsPassed) - 1] = False\n            print('Failed Test: {}'.format(message))\n    \n    # Test that correct structure is returned\n    testsPassed.append(None)\n    try:\n        assert isinstance(output, tuple)\n        assert len(output) == 3\n        assert isinstance(output[0], DataFrame)\n        assert isinstance(output[1], int)\n        assert isinstance(output[2], float)\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")\n        \n    # Test that correct result is returned\n    testsPassed.append(None)\n    try:\n        assert output[0].rdd.collect() == testFunction().rdd.collect()\n        assert output[1] == testFunction().count()\n        assert output[2] > 0 and output[2] < 10000\n        passedTest(True)\n    except:\n        passedTest(False, \"Correct structure not returned for benchmarkCount\")    \n     \n    # Print final info and return\n    if all(testsPassed):\n        print('All {} tests for benchmarkCount passed'.format(len(testsPassed)))\n        return True\n    else:\n        print('{} of {} tests for benchmarkCount passed'.format(testsPassed.count(True), len(testsPassed)))\n        return False\n\nfunctionPassed(testBenchmarkCount()) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a82f77cf-2ac1-4589-9c93-30fbbc27aba6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Test **`untilStreamIsReady()`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"befc3628-c8af-483c-bb04-8caa5279dcfa"}}},{"cell_type":"code","source":["dataPath = \"dbfs:/mnt/training/definitive-guide/data/activity-data-stream.json\"\ndataSchema = \"Recorded_At timestamp, Device string, Index long, Model string, User string, _corrupt_record String, gt string, x double, y double, z double\"\n\ninitialDF = (spark\n  .readStream                            # Returns DataStreamReader\n  .option(\"maxFilesPerTrigger\", 1)       # Force processing of only 1 file per trigger \n  .schema(dataSchema)                    # Required for all streaming DataFrames\n  .json(dataPath)                        # The stream's source directory and file type\n)\n\nname = \"Testing_123\"\n\ndisplay(initialDF, streamName = name)\nuntilStreamIsReady(name)\nassert len(spark.streams.active) == 1, \"Expected 1 active stream, found \" + str(len(spark.streams.active))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5d07c75-849e-41bd-b7c0-e707f2d0e665"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for stream in spark.streams.active:\n  stream.stop()\n  queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  while (len(queries) > 0):\n    time.sleep(5) # Give it a couple of seconds\n    queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  print(\"\"\"The stream \"{}\" has been terminated.\"\"\".format(stream.name))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a5bc6e1-ff9e-4f9d-b461-f88303b0ee08"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if all(pythonTests):\n    print('All {} tests for Python passed'.format(len(pythonTests)))\nelse:\n    print('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))\n    raise Exception('{} of {} tests for Python passed'.format(pythonTests.count(True), len(pythonTests)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fab955cd-9af4-4158-acf6-cb32d0236bad"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Utility-Methods-Test","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3256439173736211}},"nbformat":4,"nbformat_minor":0}
