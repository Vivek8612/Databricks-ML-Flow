%md
# Intro to data science in Databricks notebooks

Prefer another notebooking environment? 
* [Databricks Connect for any IDE](https://docs.databricks.com/dev-tools/databricks-connect.html)
* [Jupyter Labs (coming soon!)](https://databricks.com/blog/2019/12/03/jupyterlab-databricks-integration-bridge-local-and-remote-workflows.html)
* [Hosted R Studio](https://docs.databricks.com/spark/latest/sparkr/rstudio.html)

###################################################################################################################################################################################

%md ## Use widgets in a notebook

Databrick utilites (e.g. `dbutils`) provides functionality for many common tasks within Databricks notebooks: 
https://docs.databricks.com/dev-tools/databricks-utils.html

One useful feature is "Widgets" that allow you to dynamically program within your notebooks: https://docs.databricks.com/notebooks/widgets.html

###################################################################################################################################################################################

#Uncomment this to remove all widgets
dbutils.widgets.removeAll()

###################################################################################################################################################################################

dbutils.widgets.dropdown("dropdown_widget", "1", [str(x) for x in range(1, 4)])

###################################################################################################################################################################################

print("The current value of the dropdown_widget is:", dbutils.widgets.get("dropdown_widget"))

###################################################################################################################################################################################

dbutils.widgets.text("text_widget","Hello World!")

###################################################################################################################################################################################

# %sql
# SELECT 
#   COUNT(c1),
#   getArgument("text_widget")
# FROM (VALUES (1)) t1(c1)

###################################################################################################################################################################################

%md ## Magic Commands with "%"
Switch between Python, R, SQL, and Scala within the same notebook

###################################################################################################################################################################################

%scala
val x = 1
x+x

###################################################################################################################################################################################

%md
Or interact programmatically with the file system:

###################################################################################################################################################################################

%fs ls
/databricks-datasets/

###################################################################################################################################################################################

%md
## Environment Management
In Machine Learning Runtime, you can use Conda for environment management

###################################################################################################################################################################################

%conda info --envs

###################################################################################################################################################################################

%md 
"Notebook-scoped libraries" can be used to install libraries only for a particular notebook in Databricks Runtime 
* Notebook-scoped Libraries [Blog](https://databricks.com/blog/2019/01/08/introducing-databricks-library-utilities-for-notebooks.html) | [Databricks Utilities]()
* For Machine Learning Runtime, use Conda or Pip for environment management: [Notebook Scoped Python Libraries](https://docs.databricks.com/notebooks/notebooks-python-libraries.html)

###################################################################################################################################################################################

#%pip install pandas

###################################################################################################################################################################################

%md 
# Data Exploration Basics

###################################################################################################################################################################################

import pandas as pd
df = pd.read_csv('/dbfs/databricks-datasets/bikeSharing/data-001/day.csv')

###################################################################################################################################################################################

#In-line tabular data with "display()" command
display(df)

###################################################################################################################################################################################

#In-line charts
display(df)

###################################################################################################################################################################################

# Use your favorite charting library
import numpy as np
import matplotlib.pyplot as plt

points, zorder1, zorder2 = 500, 10, 5
x = np.linspace(0, 1, points)
y = np.sin(4 * np.pi * x) * np.exp(-5 * x)

fig, ax = plt.subplots()

ax.fill(x, y, zorder=zorder1)
ax.grid(True, zorder=zorder2)
plt.show()
display() # Databricks display
plt.close() # Ensure you close it

###################################################################################################################################################################################

%md
# Revision History Tracking 
From within a notebook, click the right-most Revision History button to see all past versions of the notebook. 

Click Restore if you want to revert the notebook to a previous version

###################################################################################################################################################################################

%md
# Collaboration
Try this:
1. Hi-light code
2. A small bubble should appear on the right-hand side
3. Any code (Python, markdown, etc.) can be commented this way

###################################################################################################################################################################################

1+1

###################################################################################################################################################################################

%md 
# Quickly Share your Findings
After your exploratory data science work, share your findings via: 
1. Dashboard: In the top utility bar, click the drop-down to create a new dashboard. Or click the small chart icon at the top-right of each cell
2. Export a notebook to HTML to be viewed in any browser. 

###################################################################################################################################################################################

display(df)






